# app/services/enhanced_dialogue.py


from __future__ import annotations
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum
import logging

from app.services.storage import ConversationDocument
from app.services.question_bank import QuestionBank
from app.services.ai_routing import AIRouter
from app.services.pnm_scoring import PNMScoringEngine
from app.services.ai_scoring_engine import AIFreeTextScorer, EnhancedPNMScorer, StageScorer
from app.services.user_profile_manager import UserProfileManager, ReliableRoutingEngine
from app.vendors.ibm_cloud import RAGQueryClient, LLMClient
import hashlib
import json

log = logging.getLogger(__name__)


# ConversationCache class removed - unused dead code
  


class ConversationMode(Enum):
    """Conversation mode types"""
    FREE_DIALOGUE = "free_dialogue"           # Mode 1: Natural conversation with RAG AI
    DIMENSION_ANALYSIS = "dimension_analysis" # Mode 2: Structured dimension assessment
    TRANSITIONING = "transitioning"           # Intermediate state during mode switches


class ResponseType(Enum):
    """Response content types"""
    CHAT = "chat"                            # Normal conversational response
    QUESTION = "question"                    # Structured assessment question
    SUMMARY = "summary"                      # Detailed summary after completing assessments


@dataclass
class ConversationContext:
    """Context information for conversation processing"""
    conversation: ConversationDocument
    user_input: str
    mode: ConversationMode
    turn_count: int
    detected_symptoms: List[str]
    current_dimension: Optional[str]
    current_term: Optional[str]
    recent_scores: List[Dict[str, Any]]
    
    
@dataclass
class DialogueResponse:
    """Enhanced response structure"""
    content: str
    response_type: ResponseType
    mode: ConversationMode
    
    # Conversation control
    should_continue_dialogue: bool = True
    next_mode: Optional[ConversationMode] = None
    
    # Assessment data
    current_pnm: Optional[str] = None
    current_term: Optional[str] = None
    question_id: Optional[str] = None
    options: Optional[List[Dict[str, Any]]] = None

    # Information cards
    info_cards: Optional[List[Dict[str, Any]]] = None
    detected_symptoms: Optional[List[str]] = None

    # Enhanced info provider integration
    has_info_cards: bool = False

    # Metadata
    confidence_score: float = 0.0
    rag_sources: Optional[List[str]] = None

    # Scoring data
    score: Optional[float] = None
    scoring_method: Optional[str] = None
    rationale: Optional[str] = None


class ConversationModeManager:
    """
    Central manager for conversation modes and transitions.
    """
    
    def __init__(self, qb: QuestionBank, ai_router: AIRouter, storage=None):
        self.qb = qb
        self.ai_router = ai_router
        self.storage = storage  # Add storage for UC1 scoring
        self.scoring_engine = PNMScoringEngine()
        self.enhanced_pnm_scorer = EnhancedPNMScorer()
        self.ai_scorer = AIFreeTextScorer(ai_router)
        self.stage_scorer = StageScorer()
        self.profile_manager = UserProfileManager()
        self.reliable_router = ReliableRoutingEngine()

        # Initialize LLM BEFORE UC managers to ensure dependency access
        self.llm = LLMClient()

        # Use Case specific managers - clean separation (initialize AFTER LLM)
        self.uc1_manager = UseCaseOneManager(qb, ai_router, self)  # Pass main manager for storage access
        self.uc2_manager = UseCaseTwoManager(qb, ai_router, self)  # Pass main manager for scoring access
        
    def determine_conversation_mode(self, context: ConversationContext) -> ConversationMode:
        """
        Determine which conversation mode to use.

        STEP 1: Basic rules
        STEP 2: Add AI decision making
        STEP 3: Add user preference learning
        """
        # Use Case 2: Explicit dimension selection from frontend
        if (context.conversation.type == "dimension" and
            context.conversation.dimension):
            return ConversationMode.DIMENSION_ANALYSIS

        # Use Case 1: Start with FREE_DIALOGUE for first 3 turns
        # Only transition to assessment after sufficient dialogue
        if context.turn_count <= 3:
            # Force free dialogue for first 3 turns (turns 1, 2, 3)
            return ConversationMode.FREE_DIALOGUE

        # After turn 3, allow transition based on should_transition_mode()
        return ConversationMode.FREE_DIALOGUE
    
    def should_transition_mode(self, context: ConversationContext) -> bool:
        """
        Determine if conversation should transition to different mode.

        STEP 1: Basic transition triggers
        STEP 2: AI-powered transition detection
        STEP 3: Refined transition logic
        """
        if context.mode == ConversationMode.FREE_DIALOGUE:
            # Simple turn-based transition - no keyword matching
            # After 3 turns of pure dialogue, transition to assessment
            if context.turn_count >= 4:
                return True  # Start assessment from turn 4

            # Optional: Keep only very explicit user requests for assessment
            if "start assessment" in context.user_input.lower() or "begin evaluation" in context.user_input.lower():
                return True  # User explicitly requests assessment

        return False
        
    async def process_conversation(self, context: ConversationContext) -> DialogueResponse:
        """
        Main entry point for conversation processing.
        Routes to appropriate Use Case manager.
        """
        try:
            pass  # Debug print removed
        except Exception as e:
            print(f"[ERROR] Exception accessing context attributes: {e}")
            print(f"[ERROR] Context type: {type(context)}")
            print(f"[ERROR] Context.conversation type: {type(context.conversation) if hasattr(context, 'conversation') else 'No conversation attr'}")
            raise e  # Re-raise to trigger fallback to legacy system

        # Route based on conversation type - clean separation

        if (context.conversation.type == "dimension" and
            context.conversation.dimension):
            # Use Case 2: Single dimension assessment
            return await self.uc2_manager.handle_dimension_assessment(
                context, context.conversation.dimension)
        else:
            # Use Case 1: General conversation flow
            return await self.uc1_manager.handle_conversation_flow(context)
    
    
    
    def _handle_fallback(self, context: ConversationContext) -> DialogueResponse:
        """Fallback response when other modes fail"""
        return DialogueResponse(
            content="How are you feeling about your current situation with ALS?",
            response_type=ResponseType.CHAT,
            mode=ConversationMode.FREE_DIALOGUE,
            should_continue_dialogue=True
        )
    
    def _fallback_dimension_analysis(self, context: ConversationContext) -> DialogueResponse:
        """Fallback for dimension analysis mode"""
        try:
            # Only do PNM routing if we're truly in assessment mode
            # Use Case 1: Don't auto-route to dimensions during free dialogue
            if (context.conversation.type == "dimension" and context.conversation.dimension):
                # Use Case 2: Explicit dimension assessment
                pnm = context.conversation.dimension
                term = context.current_term or 'General health'
            elif context.current_dimension:
                # Assessment mode with existing dimension
                pnm = context.current_dimension
                term = context.current_term or 'General health'
            else:
                # Use Case 1: Should not reach here - redirect to free dialogue
                return self._handle_fallback(context)
            
            question_item = self.qb.choose_for_term(pnm, term, [])
            if question_item:
                options = []
                if question_item.options:
                    options = [
                        {'value': opt.get('id', str(i)), 'label': opt.get('label', str(opt))}
                        for i, opt in enumerate(question_item.options)
                    ]
                
                return DialogueResponse(
                    content=question_item.main,
                    response_type=ResponseType.CHAT,
                    mode=ConversationMode.DIMENSION_ANALYSIS,
                    current_pnm=pnm,
                    current_term=term,
                    question_id=question_item.id,
                    options=options,
                    should_continue_dialogue=True
                )
        except Exception as e:
            log.error(f"Fallback dimension analysis error: {e}")
        
        return self._handle_fallback(context)


class TransitionDetector:
    """
    AI-powered detection of conversation transitions.
    
    STEP 2: Full implementation with LLM-based decision making
    """
    
    def __init__(self, rag: RAGQueryClient, llm: LLMClient):
        self.rag = rag
        self.llm = llm
        
    def should_start_assessment(self, context: ConversationContext) -> bool:
        """
        AI-powered determination of assessment readiness.
        
        STEP 2: Uses multiple signals and LLM judgment
        """
        try:
            # Rule-based triggers (quick checks)
            if self._check_rule_based_triggers(context):
                return True
            
            # AI-powered analysis for complex cases
            if context.turn_count >= 2:  # Only use AI after sufficient dialogue
                return self._ai_assess_transition_readiness(context)
            
            return False
            
        except Exception as e:
            log.error(f"Transition assessment error: {e}")
            # Fallback to simple rule
            return context.turn_count >= 5
    
    def _check_rule_based_triggers(self, context: ConversationContext) -> bool:
        """Fast rule-based transition triggers"""
        # Explicit assessment requests
        user_input_lower = context.user_input.lower()
        assessment_keywords = [
            'assess', 'evaluate', 'test', 'check', 'questionnaire', 'survey',
            'how am i doing', 'what about my', 'need help with'
        ]
        
        if any(keyword in user_input_lower for keyword in assessment_keywords):
            return True
        
        # Removed symptom-based complexity detection - use turn count instead
        
        # Extended conversation without assessment
        if context.turn_count >= 7:
            return True
        
        # Removed distress keyword matching - these are common words that cause false triggers
        # Let AI assess emotional state through natural conversation analysis instead
        
        return False
    
    def _ai_assess_transition_readiness(self, context: ConversationContext) -> bool:
        """Use LLM to assess if user is ready for structured assessment"""
        try:
            # Build conversation history for AI analysis
            recent_messages = [
                f"{'User' if msg.role == 'user' else 'Assistant'}: {msg.content}"
                for msg in context.conversation.messages[-4:]  # Last 4 messages
            ]
            conversation_history = "\n".join(recent_messages)
            
            # Construct AI prompt for transition assessment
            prompt = f"""Analyze this ALS patient conversation to determine if they're ready for structured assessment.

CONVERSATION HISTORY:
{conversation_history}

CURRENT CONTEXT:
- Turn count: {context.turn_count}
- Detected symptoms: {', '.join(context.detected_symptoms) if context.detected_symptoms else 'None'}
- Current mode: Free dialogue

ASSESSMENT READINESS INDICATORS:
- User expressing specific concerns that need structured evaluation
- Mentioning multiple symptoms or challenges that warrant assessment
- Showing readiness for more detailed discussion
- Asking for guidance or structured help
- Showing signs of wanting to move beyond general chat

DECISION CRITERIA:
- Is the user ready for structured questions about their ALS experience?
- Would an assessment help them better than continued free dialogue?
- Are they showing engagement that would benefit from structured approach?

Respond with only: "YES" (ready for assessment) or "NO" (continue free dialogue)

Decision:"""

            # Get LLM decision
            response = self.llm.generate_text(prompt)
            
            # Parse response
            return response.strip().upper().startswith('YES')
            
        except Exception as e:
            log.error(f"AI transition assessment error: {e}")
            # Fallback to conservative approach
            return False
    
    def detect_completion_readiness(self, context: ConversationContext) -> bool:
        """
        AI-powered detection of assessment term completion.
        
        STEP 2: Analyzes response quality and coverage
        """
        try:
            # Quick rule-based checks
            if self._check_completion_rules(context):
                return True
            
            # AI analysis of response depth and completeness
            if context.turn_count >= 2:
                return self._ai_assess_completion_readiness(context)
            
            return False
            
        except Exception as e:
            log.error(f"Completion assessment error: {e}")
            # Fallback to simple rule
            return False
    
    def _check_completion_rules(self, context: ConversationContext) -> bool:
        """Rule-based completion detection"""
        # User indicates they're done or want to move on
        user_input_lower = context.user_input.lower()
        completion_indicators = [
            'that\'s all', 'nothing else', 'move on', 'next topic', 'done with',
            'covered everything', 'ready for next', 'what else'
        ]
        
        if any(indicator in user_input_lower for indicator in completion_indicators):
            return True
        
        # Very short responses might indicate completion
        if len(context.user_input.strip()) < 20 and context.turn_count >= 3:
            return True
        
        return False
    
    def _ai_assess_completion_readiness(self, context: ConversationContext) -> bool:
        """Use LLM to assess if term assessment is complete"""
        try:
            # Get recent user responses for this term
            term_responses = []
            for msg in context.conversation.messages:
                if (msg.role == 'user' and 
                    hasattr(msg, 'metadata') and 
                    msg.metadata.get('current_term') == context.current_term):
                    term_responses.append(msg.content)
            
            # Use last 3 responses
            recent_responses = term_responses[-3:] if term_responses else [context.user_input]
            
            prompt = f"""Analyze ALS patient responses to determine if this assessment topic is sufficiently covered.

ASSESSMENT TOPIC: {context.current_dimension} - {context.current_term}

PATIENT RESPONSES:
{chr(10).join(f"Response {i+1}: {resp}" for i, resp in enumerate(recent_responses))}

COMPLETION CRITERIA:
- Has patient provided substantive information about this topic?
- Are their responses detailed enough to understand their situation?
- Have they expressed their main concerns and experiences?
- Would additional questions on this topic provide significant new insights?

DECISION FACTORS:
- Response depth and detail level
- Coverage of key aspects of the topic
- Patient engagement and communication quality
- Indication they've shared what's important to them

Respond with only: "COMPLETE" (ready for summary) or "CONTINUE" (needs more questions)

Assessment:"""

            # Get LLM decision
            response = self.llm.generate_text(prompt)
            
            # Parse response
            return response.strip().upper().startswith('COMPLETE')
            
        except Exception as e:
            log.error(f"AI completion assessment error: {e}")
            return False
    
    def detect_emotional_state_change(self, context: ConversationContext) -> Optional[str]:
        """
        Advanced emotional state detection with LLM analysis and pattern learning.
        
        STEP 3: Enhanced emotion analysis with context awareness and personality adaptation
        """
        try:
            if context.turn_count < 2:
                return None
            
            # Multi-layer emotion detection combining keywords + LLM + patterns
            keyword_emotion = self._detect_emotion_keywords(context.user_input)
            llm_emotion = self._detect_emotion_llm(context)
            pattern_emotion = self._detect_emotion_patterns(context)
            
            # Weighted combination of detection methods
            final_emotion = self._combine_emotion_signals(keyword_emotion, llm_emotion, pattern_emotion)
            
            # Store emotion history for learning
            self._store_emotion_history(context, final_emotion)
            
            return final_emotion
            
        except Exception as e:
            log.error(f"Advanced emotional state detection error: {e}")
            # Fallback to simple keyword detection
            return self._detect_emotion_keywords(context.user_input)
    
    def _detect_emotion_keywords(self, user_input: str) -> Optional[str]:
        """Enhanced keyword-based emotion detection"""
        current_input = user_input.lower()
        
        emotional_states = {
            'severe_distress': ['terrified', 'panic', 'can\'t cope', 'breakdown', 'overwhelmed'],
            'distress': ['scared', 'frightened', 'worried sick', 'devastated'],
            'sadness': ['sad', 'depressed', 'hopeless', 'crying', 'down'],
            'anger': ['angry', 'furious', 'frustrated', 'mad', 'unfair'],
            'anxiety': ['worried', 'anxious', 'nervous', 'afraid', 'concerned'],
            'hope': ['better', 'improving', 'hopeful', 'positive', 'grateful'],
            'confusion': ['confused', 'don\'t understand', 'lost', 'unclear'],
            'acceptance': ['accepting', 'coming to terms', 'peaceful', 'ready']
        }
        
        # Check for intensity markers
        intensity_markers = ['very', 'extremely', 'really', 'so', 'completely']
        has_intensity = any(marker in current_input for marker in intensity_markers)
        
        for state, keywords in emotional_states.items():
            if any(keyword in current_input for keyword in keywords):
                # Upgrade emotion if intensity markers present
                if has_intensity and state == 'distress':
                    return 'severe_distress'
                return state
        
        return None
    
    def _detect_emotion_llm(self, context: ConversationContext) -> Optional[str]:
        """LLM-based emotion analysis for nuanced detection"""
        try:
            # Build emotion analysis prompt
            prompt = f"""
Analyze the emotional state in this conversation context for an ALS patient:

Recent conversation:
{self._get_conversation_history(context, 3)}

Current message: "{context.user_input}"

Detected symptoms: {', '.join(context.detected_symptoms) if context.detected_symptoms else 'None'}

Identify the primary emotional state from: severe_distress, distress, sadness, anger, anxiety, hope, confusion, acceptance, neutral

Consider:
- ALS-specific emotional challenges
- Disease progression concerns
- Support network dynamics
- Coping mechanisms

Return only the emotional state or 'neutral' if unclear.
"""
            
            response = self.llm.generate_text(prompt)
            emotion = response.strip().lower()
            
            # Validate emotion response
            valid_emotions = ['severe_distress', 'distress', 'sadness', 'anger', 'anxiety', 'hope', 'confusion', 'acceptance', 'neutral']
            if emotion in valid_emotions:
                return emotion if emotion != 'neutral' else None
                
        except Exception as e:
            log.warning(f"LLM emotion detection failed: {e}")
        
        return None
    
    def _detect_emotion_patterns(self, context: ConversationContext) -> Optional[str]:
        """Pattern-based emotion detection using conversation history"""
        try:
            # Analyze conversation patterns
            messages = context.conversation.messages[-5:] if context.conversation.messages else []
            
            # Look for escalating emotional patterns
            user_messages = [msg.content for msg in messages if msg.role == 'user']
            if len(user_messages) >= 2:
                # Check for repeated emotional themes
                recent_text = ' '.join(user_messages[-2:]).lower()
                
                # Pattern indicators
                repetition_patterns = {
                    'anxiety': ['keep worrying', 'can\'t stop thinking', 'what if'],
                    'sadness': ['getting worse', 'losing hope', 'giving up'],
                    'anger': ['not fair', 'why me', 'angry'],
                    'hope': ['trying', 'working on', 'getting better']
                }
                
                for emotion, patterns in repetition_patterns.items():
                    if any(pattern in recent_text for pattern in patterns):
                        return emotion
                        
        except Exception as e:
            log.warning(f"Pattern emotion detection failed: {e}")
        
        return None
    
    def _combine_emotion_signals(self, keyword: Optional[str], llm: Optional[str], pattern: Optional[str]) -> Optional[str]:
        """Intelligently combine multiple emotion detection signals"""
        # Priority: LLM > Pattern > Keywords (LLM is most context-aware)
        if llm:
            # Validate with other signals
            if keyword and keyword == llm:
                return llm  # High confidence
            elif pattern and pattern == llm:
                return llm  # Medium-high confidence
            else:
                return llm  # LLM-only detection
        
        if pattern and keyword and pattern == keyword:
            return pattern  # Cross-validated
        
        # Fallback to strongest signal
        return pattern or keyword
    
    def _store_emotion_history(self, context: ConversationContext, emotion: Optional[str]):
        """Store emotion history for learning and adaptation"""
        try:
            if not emotion:
                return
                
            # Store in conversation assessment state
            if 'emotion_history' not in context.conversation.assessment_state:
                context.conversation.assessment_state['emotion_history'] = []
            
            emotion_entry = {
                'turn': context.turn_count,
                'emotion': emotion,
                'timestamp': context.conversation.created_at.isoformat() if context.conversation.created_at else None,
                'user_input_length': len(context.user_input),
                'detected_symptoms': context.detected_symptoms.copy()
            }
            
            context.conversation.assessment_state['emotion_history'].append(emotion_entry)
            
            # Keep only last 20 emotion entries
            if len(context.conversation.assessment_state['emotion_history']) > 20:
                context.conversation.assessment_state['emotion_history'] = context.conversation.assessment_state['emotion_history'][-20:]
                
        except Exception as e:
            log.warning(f"Failed to store emotion history: {e}")
    
    def _get_conversation_history(self, context: ConversationContext, num_turns: int = 3) -> str:
        """Get recent conversation history for context"""
        try:
            messages = context.conversation.messages[-num_turns*2:] if context.conversation.messages else []
            history = []
            
            for msg in messages:
                role = "Patient" if msg.role == 'user' else "Assistant"
                history.append(f"{role}: {msg.content}")
            
            return '\n'.join(history)
        except Exception:
            return "No conversation history available"


class ResponseGenerator:
    """
    RAG + LLM powered response generation with advanced personalization.
    
    STEP 3: Enhanced with user behavior learning and preference adaptation
    """
    
    def __init__(self, rag: RAGQueryClient = None, llm: LLMClient = None):
        self.rag = rag or RAGQueryClient()
        self.llm = llm or LLMClient()
        
        # Load conversation style configuration
        self.conversation_config = self._load_conversation_config()
        
        # Load PNM lexicon for symptom understanding
        self.pnm_lexicon = self._load_pnm_lexicon()
        
        # Removed user behavior analyzer - over-engineered keyword matching system
        
        # REMOVED OBSOLETE COMPONENTS:
        # - ConversationCache: Over-engineered caching not needed for UC1/UC2
        # - ConversationCoherenceTracker: Complex coherence analysis not required
        # - DynamicKnowledgeExpander: Over-complex knowledge expansion not needed
        
        # Enhanced info provider removed - zombie code cleanup
        
    def _load_conversation_config(self) -> Dict[str, Any]:
        """Load conversation style configuration"""
        try:
            import json
            from pathlib import Path
            config_path = Path(__file__).parent.parent / "data" / "conversation_config.json"
            if config_path.exists():
                return json.loads(config_path.read_text())
        except Exception as e:
            log.warning(f"Could not load conversation config: {e}")
        
        # Fallback default config
        return {
            "language_style": {
                "avoid_clinical_jargon": True,
                "use_simple_language": True,
                "max_sentence_length": 20,
                "active_voice": True
            },
            "empathy_rules": {
                "acknowledge_difficulty": True,
                "validate_feelings": True,
                "offer_hope": True,
                "respect_autonomy": True
            }
        }
    
    def _load_pnm_lexicon(self) -> Dict[str, Any]:
        """Load PNM lexicon for symptom understanding"""
        try:
            import json
            from pathlib import Path
            lexicon_path = Path(__file__).parent.parent / "data" / "pnm_lexicon.json"
            if lexicon_path.exists():
                return json.loads(lexicon_path.read_text())
        except Exception as e:
            log.warning(f"Could not load PNM lexicon: {e}")
        
        return {}
        
    def generate_chat_response(self, context: ConversationContext) -> str:
        """
        Generate personalized RAG+LLM powered conversational response.
        
        STEP 3: Enhanced with user behavior learning and advanced personalization:
        1. User preference analysis and adaptation
        2. Symptom-aware RAG retrieval with personalization
        3. Context-sensitive LLM generation with emotional intelligence
        4. Adaptive response styling based on learned preferences
        """
        try:
            # 1. Simplified user preferences - no keyword matching overhead
            user_preferences = {'communication_style': 'balanced'}

            # 2. Analyze user input with enhanced context awareness
            analysis = self._analyze_user_input_enhanced(context, user_preferences)

            # 3. Retrieve knowledge via RAG
            knowledge = self._retrieve_personalized_knowledge(context, analysis, user_preferences)
            
            # 4. REMOVED: Conversation coherence analysis (over-engineered for UC1/UC2)
            coherence_analysis = {'coherence_score': 0.8, 'suggestions': []}  # Simple fallback
            
            # 5. Decide response mode: Chat vs Info Cards
            should_provide_info = self._should_provide_info_cards(context, analysis, user_preferences)
            
            if should_provide_info:
                # Generate response with info cards
                response = self._generate_chat_with_info_cards(context, analysis, knowledge, user_preferences, coherence_analysis)
            else:
                # Generate pure conversational response
                response = self._generate_adaptive_response(context, analysis, knowledge, user_preferences, coherence_analysis)
            
            return response
            
        except Exception as e:
            log.error(f"Advanced chat response generation error: {e}")
            # Fallback to enhanced empathetic response with basic preferences
            return self._generate_enhanced_fallback_response(context)
    
    def _analyze_user_input(self, context: ConversationContext) -> Dict[str, Any]:
        """Analyze user input for symptoms, emotions, and intent"""
        user_input = context.user_input.lower()
        
        analysis = {
            'detected_symptoms': context.detected_symptoms.copy(),
            'emotional_indicators': [],
            'urgency_level': 'normal',
            'key_topics': [],
            'requires_support': False
        }
        
        # Enhanced symptom detection using PNM lexicon
        for pnm_level, pnm_data in self.pnm_lexicon.items():
            if 'terms' in pnm_data:
                for term, synonyms in pnm_data['terms'].items():
                    if any(synonym.lower() in user_input for synonym in synonyms):
                        if term not in analysis['detected_symptoms']:
                            analysis['detected_symptoms'].append(term.lower())
                        analysis['key_topics'].append(term)
        
        # Emotional state detection
        emotional_keywords = {
            'distressed': ['scared', 'worried', 'anxious', 'frightened', 'panic', 'terrified'],
            'sad': ['sad', 'depressed', 'down', 'hopeless', 'discouraged'],
            'frustrated': ['frustrated', 'angry', 'mad', 'annoyed', 'upset'],
            'positive': ['better', 'good', 'improving', 'hopeful', 'grateful']
        }
        
        for emotion, keywords in emotional_keywords.items():
            if any(keyword in user_input for keyword in keywords):
                analysis['emotional_indicators'].append(emotion)
        
        # Urgency detection
        urgent_keywords = ['emergency', 'urgent', 'immediately', 'hospital', 'can\'t breathe', 'choking']
        if any(keyword in user_input for keyword in urgent_keywords):
            analysis['urgency_level'] = 'urgent'
        
        # Support need detection
        support_keywords = ['help', 'don\'t know', 'confused', 'alone', 'support']
        if any(keyword in user_input for keyword in support_keywords):
            analysis['requires_support'] = True
        
        return analysis
    
    def _retrieve_contextual_knowledge(self, context: ConversationContext, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Retrieve relevant knowledge based on context and analysis with caching"""
        try:
            knowledge = []
            
            # Primary query based on detected symptoms
            if analysis['detected_symptoms']:
                primary_symptoms = analysis['detected_symptoms'][:2]  # Focus on top 2 symptoms
                query = f"ALS {' '.join(primary_symptoms)} management support care"
                
                # Direct RAG search (removed caching for simplicity)
                rag_results = self.rag.search(query, top_k=3, index_kind="background")
                knowledge.extend(rag_results)
            
            # Secondary query for emotional support if needed
            if analysis['emotional_indicators'] and analysis['requires_support']:
                emotion_query = f"ALS emotional support coping {analysis['emotional_indicators'][0]}"
                
                # Direct RAG search (removed caching for simplicity)
                emotion_results = self.rag.search(emotion_query, top_k=2, index_kind="background")
                knowledge.extend(emotion_results)
            
            # Tertiary query for general conversation continuation
            if not knowledge and context.turn_count > 1:
                # Use conversation history for context
                recent_topics = ' '.join([msg.content for msg in context.conversation.messages[-2:] if msg.role == 'user'])
                if recent_topics:
                    general_query = f"ALS patient conversation {recent_topics[:100]}"
                    
                    # Direct RAG search (removed caching for simplicity)
                    general_results = self.rag.search(general_query, top_k=2, index_kind="background")
                    knowledge.extend(general_results)
            
            return knowledge[:4]  # Limit to top 4 most relevant pieces
            
        except Exception as e:
            log.warning(f"RAG retrieval error: {e}")
            return []
    
    def _generate_empathetic_response(self, context: ConversationContext, analysis: Dict[str, Any], knowledge: List[Dict[str, Any]]) -> str:
        """Generate empathetic response using LLM with RAG knowledge and caching"""
        try:
            # Construct LLM prompt with context and knowledge
            prompt = self._build_chat_prompt(context, analysis, knowledge)
            
            # Direct LLM generation (removed caching for simplicity)
            response = self.llm.generate_text(prompt)
            
            # Clean and validate response
            return self._clean_and_validate_response(response, context)
            
        except Exception as e:
            log.error(f"LLM generation error: {e}")
            return self._generate_fallback_response(context)
    
    def _create_context_hash(self, context: ConversationContext, analysis: Dict[str, Any]) -> str:
        """Create hash representing conversation context for caching"""
        try:
            # Create hash from key context elements (not user-specific data)
            context_elements = {
                'mode': context.mode.value,
                'symptoms': sorted(analysis.get('detected_symptoms', [])),
                'emotional_state': sorted(analysis.get('emotional_indicators', [])),
                'urgency': analysis.get('urgency_level', 'normal'),
                'turn_range': f"{(context.turn_count // 5) * 5}-{((context.turn_count // 5) + 1) * 5}"  # Group by 5-turn ranges
            }
            
            context_str = json.dumps(context_elements, sort_keys=True)
            return hashlib.md5(context_str.encode()).hexdigest()[:16]
            
        except Exception:
            return "default"
    
    def _build_chat_prompt(self, context: ConversationContext, analysis: Dict[str, Any], knowledge: List[Dict[str, Any]]) -> str:
        """Build comprehensive prompt for LLM generation"""
        # Extract empathy rules from config
        empathy_rules = self.conversation_config.get('empathy_rules', {})
        language_style = self.conversation_config.get('language_style', {})
        
        # Build knowledge context
        knowledge_text = "\n".join([
            f"- {doc.get('text', '')[:200]}..." for doc in knowledge[:2]
        ]) if knowledge else "No specific knowledge retrieved."
        
        # Build conversation history context
        recent_messages = [
            f"User: {msg.content}" for msg in context.conversation.messages[-3:] 
            if msg.role == 'user'
        ]
        history_context = "\n".join(recent_messages) if recent_messages else "No previous conversation."
        
        prompt = f"""You're an ALS support assistant. They said: "{context.user_input}"

Recent conversation:
{history_context}

Helpful information:
{knowledge_text}

Give a short, caring response (2-3 sentences max). Share one useful tip if relevant. Ask a simple follow-up to keep talking."""

        return prompt
    
    def _analyze_user_input_enhanced(self, context: ConversationContext, user_preferences: Dict[str, Any]) -> Dict[str, Any]:
        """Enhanced user input analysis with preference awareness"""
        # Start with basic analysis
        analysis = self._analyze_user_input(context)
        
        # Add preference-aware enhancements
        analysis['user_preferences'] = user_preferences
        analysis['response_length_preference'] = user_preferences.get('preferred_response_length', 'balanced')
        analysis['communication_style'] = user_preferences.get('communication_style', 'balanced')
        analysis['topic_interests'] = user_preferences.get('topic_interests', [])
        analysis['support_needs'] = user_preferences.get('support_needs', [])
        analysis['engagement_level'] = self._assess_current_engagement(context, user_preferences)
        
        return analysis
    
    def _assess_current_engagement(self, context: ConversationContext, user_preferences: Dict[str, Any]) -> str:
        """Assess user's current engagement level"""
        try:
            current_length = len(context.user_input)
            engagement_patterns = user_preferences.get('engagement_patterns', {})
            avg_length = engagement_patterns.get('avg_message_length', 50)
            
            if current_length < avg_length * 0.5:
                return 'low'
            elif current_length > avg_length * 1.5:
                return 'high'
            else:
                return 'normal'
        except Exception:
            return 'normal'
    
    def _retrieve_personalized_knowledge(self, context: ConversationContext, analysis: Dict[str, Any], user_preferences: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Retrieve knowledge with personalization based on user interests and needs"""
        try:
            # Base knowledge retrieval
            knowledge = self._retrieve_contextual_knowledge(context, analysis)
            
            # Enhance with personalized topics
            topic_interests = user_preferences.get('topic_interests', [])
            support_needs = user_preferences.get('support_needs', [])
            
            # Retrieve additional knowledge for user's interests
            for topic in topic_interests[:2]:  # Top 2 interests
                topic_knowledge = self._retrieve_topic_specific_knowledge(topic, context)
                knowledge.extend(topic_knowledge)
                
                # REMOVED: Dynamic knowledge expansion (over-engineered for UC1/UC2)
            
            # Retrieve support-specific knowledge
            for need in support_needs[:2]:  # Top 2 support needs
                support_knowledge = self._retrieve_support_specific_knowledge(need, context)
                knowledge.extend(support_knowledge)
            
            # Identify and fill knowledge gaps
            # REMOVED: Dynamic knowledge gap detection and expansion (over-engineered for UC1/UC2)
            knowledge_gaps = []
            if False:  # Disabled dynamic knowledge expansion
                for topic, content_list in expanded_knowledge.items():
                    for content in content_list[:2]:  # Add top 2 pieces per topic
                        knowledge.append({
                            'text': content,
                            'metadata': {'source': 'dynamic_expansion', 'topic': topic},
                            'score': 0.85
                        })
            
            # Remove duplicates and limit results
            seen_texts = set()
            unique_knowledge = []
            for doc in knowledge:
                text = doc.get('text', '')[:100]  # First 100 chars as identifier
                if text not in seen_texts:
                    seen_texts.add(text)
                    unique_knowledge.append(doc)
                    if len(unique_knowledge) >= 5:  # Limit to top 5 results
                        break
            
            return unique_knowledge
            
        except Exception as e:
            log.warning(f"Personalized knowledge retrieval failed: {e}")
            return self._retrieve_contextual_knowledge(context, analysis)
    
    def _retrieve_topic_specific_knowledge(self, topic: str, context: ConversationContext) -> List[Dict[str, Any]]:
        """Retrieve knowledge specific to user's topic interests"""
        try:
            # Map topics to search queries
            topic_queries = {
                'mobility': 'mobility aids walking assistance wheelchair',
                'breathing': 'breathing support ventilator respiratory care',
                'speech': 'speech therapy communication aids voice',
                'eating': 'swallowing nutrition feeding eating',
                'family': 'family support caregiving relationships',
                'work': 'employment workplace accommodation',
                'emotions': 'emotional support coping mental health',
                'future': 'planning goals future care advance directives'
            }
            
            query = topic_queries.get(topic, topic)
            docs = self.rag.search(query, top_k=2, index_kind="background")
            return docs
            
        except Exception:
            return []
    
    def _retrieve_support_specific_knowledge(self, support_need: str, context: ConversationContext) -> List[Dict[str, Any]]:
        """Retrieve knowledge for specific support needs"""
        try:
            # Map support needs to targeted queries
            support_queries = {
                'respiratory_support': 'breathing assistance ventilator oxygen therapy',
                'mobility_assistance': 'mobility aids wheelchair walker assistance',
                'communication_aids': 'speech device communication technology AAC',
                'emotional_support': 'emotional coping mental health support',
                'information_support': 'ALS information education understanding',
                'hope_building': 'hope positive outcomes quality of life'
            }
            
            query = support_queries.get(support_need, support_need)
            docs = self.rag.search(query, top_k=2, index_kind="background")
            return docs
            
        except Exception:
            return []
    
    def _generate_adaptive_response(self, context: ConversationContext, analysis: Dict[str, Any], knowledge: List[Dict[str, Any]], user_preferences: Dict[str, Any], coherence_analysis: Dict[str, Any] = None) -> str:
        """Generate response adapted to user preferences and emotional state"""
        try:
            # Build adaptive prompt based on preferences and coherence
            prompt = self._build_adaptive_prompt(context, analysis, knowledge, user_preferences, coherence_analysis)
            
            # Generate response with LLM
            response = self.llm.generate_text(prompt)
            
            # Post-process response based on preferences
            final_response = self._adapt_response_style(response, user_preferences, analysis)
            
            return self._clean_and_validate_response(final_response, context)
            
        except Exception as e:
            log.error(f"Adaptive response generation error: {e}")
            return self._generate_enhanced_fallback_response(context)
    
    def _should_provide_info_cards(self, context: ConversationContext, analysis: Dict[str, Any], user_preferences: Dict[str, Any]) -> bool:
        """
        FIXED: No longer depends on broken symptom detection (3.3% accuracy).
        Uses improved routing confidence and direct user intent signals.
        """
        try:
            info_card_signals = 0
            user_input = context.user_input.lower()
            
            # 1. Info cards should trigger after follow-up questions complete, not via keyword matching
            # Removed hardcoded info_keywords - let natural conversation flow determine timing
                
            # 2. Use routing confidence from improved system (now actually reliable)
            routing_result = analysis.get('routing_result')
            if routing_result:
                # High confidence routing suggests specific medical topic
                if routing_result.confidence > 0.7 and routing_result.method != "intelligent_fallback":
                    info_card_signals += 3
                # Medium confidence still indicates structured topic
                elif routing_result.confidence > 0.5:
                    info_card_signals += 2
                    
            # 3. Medical terminology presence indicates structured information need
            medical_terms = ['symptom', 'condition', 'treatment', 'therapy', 'medication', 
                           'equipment', 'device', 'breathing', 'swallow', 'speech', 'mobility']
            if any(term in user_input for term in medical_terms):
                info_card_signals += 2
                
            # 4. User preferences for detailed information
            if user_preferences.get('preferred_response_length') == 'detailed':
                info_card_signals += 1
            if user_preferences.get('communication_style') == 'technical':
                info_card_signals += 1
                
            # 5. Support needs indicate information gap
            support_needs = user_preferences.get('support_needs', [])
            if 'information_support' in support_needs:
                info_card_signals += 2
                
            # 6. Removed question pattern matching - these are common words that cause false triggers
            # Info cards should flow naturally after assessment completion
                
            # 7. Smart timing based on conversation flow (not rigid turn counting)
            if context.turn_count >= 3:
                # If recent messages were conversational, provide info cards for variety
                recent_responses = [msg.content for msg in context.conversation.messages[-3:] if msg.role == 'assistant']
                if recent_responses and all(len(resp) < 200 for resp in recent_responses):
                    info_card_signals += 1
                    
            # 8. Emotional state suggests need for structured support
            emotional_indicators = analysis.get('emotional_indicators', [])
            if any(emotion in ['confusion', 'anxiety', 'severe_distress'] for emotion in emotional_indicators):
                info_card_signals += 2
            
            # Lower threshold since we removed unreliable symptom detection
            return info_card_signals >= 4
            
        except Exception as e:
            log.warning(f"Info card decision error: {e}")
            # Default fallback: provide info cards occasionally
            return context.turn_count > 0 and context.turn_count % 5 == 0
    
    def _generate_chat_with_info_cards(self, context: ConversationContext, analysis: Dict[str, Any], knowledge: List[Dict[str, Any]], user_preferences: Dict[str, Any], coherence_analysis: Dict[str, Any] = None) -> str:
        """Generate conversational response enhanced with information cards"""
        try:
            # 1. Generate base conversational response
            base_response = self._generate_adaptive_response(context, analysis, knowledge, user_preferences, coherence_analysis)
            
            # 2. Create info context for enhanced info provider (FIXED: use routing result instead of broken symptom detection)
            routing_result = analysis.get('routing_result')
            severity_indicators = []
            if routing_result and routing_result.keywords:
                severity_indicators = routing_result.keywords
            
            info_context = InfoContext(
                current_pnm=context.current_dimension or (routing_result.pnm if routing_result else "Physiological"),
                current_term=context.current_term or (routing_result.term if routing_result else "general"),
                last_answer=context.user_input,
                question_history=[msg.content for msg in context.conversation.messages[-3:] if msg.role == 'user'],
                severity_indicators=severity_indicators
            )
            
            # 3. Generate information cards using enhanced info provider
            try:
                info_cards = self.info_provider.get_contextual_info_cards(info_context)
                log.info(f"Generated {len(info_cards) if info_cards else 0} info cards for user")
            except Exception as e:
                log.warning(f"Info card generation failed: {e}")
                info_cards = []
            
            # 4. If we have info cards, modify the response to acknowledge them
            if info_cards:
                # Create acknowledgment based on user preferences
                if user_preferences.get('communication_style') == 'casual':
                    card_intro = "I've also found some helpful info that might be useful:"
                elif user_preferences.get('communication_style') == 'formal':
                    card_intro = "I've prepared some additional information that may be relevant:"
                else:
                    card_intro = "Here's some information that might help:"
                
                enhanced_response = f"{base_response}\n\n{card_intro}"
                
                # Store info cards in a way that can be accessed by the conversion function
                # We'll need to modify the DialogueResponse to include info_cards
                if hasattr(context.conversation, 'temp_info_cards'):
                    context.conversation.temp_info_cards = info_cards
                else:
                    # For now, log the info cards
                    log.info(f"Info cards would be attached: {[card.get('title', 'Unknown') for card in info_cards]}")
                
                return enhanced_response
            else:
                return base_response
                
        except Exception as e:
            log.error(f"Chat with info cards generation error: {e}")
            # Fallback to regular adaptive response
            return self._generate_adaptive_response(context, analysis, knowledge, user_preferences, coherence_analysis)
    
    def _build_adaptive_prompt(self, context: ConversationContext, analysis: Dict[str, Any], knowledge: List[Dict[str, Any]], user_preferences: Dict[str, Any], coherence_analysis: Dict[str, Any] = None) -> str:
        """Build prompt adapted to user preferences and style"""
        # Get style preferences
        response_length = user_preferences.get('preferred_response_length', 'balanced')
        communication_style = user_preferences.get('communication_style', 'balanced')
        topic_interests = user_preferences.get('topic_interests', [])
        support_needs = user_preferences.get('support_needs', [])
        
        # Build length instruction
        length_instructions = {
            'simple': 'Keep response to 1 short sentence. Be concise and direct.',
            'balanced': 'Use 1-2 sentences for a thoughtful but concise response.',
            'detailed': 'Provide a thorough response with 2-3 sentences, including helpful details.'
        }
        
        # Build style instruction
        style_instructions = {
            'casual': 'Use warm, friendly, conversational language like talking to a friend.',
            'formal': 'Use respectful, gentle, and slightly more formal language.',
            'technical': 'Include relevant medical terminology when helpful, but explain it simply.',
            'balanced': 'Use warm, professional language that is both caring and informative.'
        }
        
        # Build knowledge context
        knowledge_text = "\n".join([
            f"- {doc.get('text', '')[:150]}..." for doc in knowledge[:3]
        ]) if knowledge else "No specific knowledge retrieved."
        
        # Build conversation history
        history_context = self._get_conversation_history(context, 3)
        
        # Build coherence guidance
        coherence_guidance = ""
        if coherence_analysis:
            coherence_score = coherence_analysis.get('coherence_score', 1.0)
            current_topic = coherence_analysis.get('current_topic', 'general')
            suggestions = coherence_analysis.get('suggestions', [])  # Use fallback suggestions
            
            coherence_guidance = f"""
CONVERSATION COHERENCE ANALYSIS:
- Current topic: {current_topic}
- Coherence score: {coherence_score:.1f}/1.0
- Topic continuity: {coherence_analysis.get('topic_continuity', {}).get('type', 'normal')}
- Reference clarity: {'Good' if coherence_analysis.get('reference_resolution', {}).get('score', 1.0) > 0.7 else 'Needs attention'}
- Flow quality: {coherence_analysis.get('conversation_flow', {}).get('quality', 'good')}
{f"- Improvement suggestions: {'; '.join(suggestions[:2])}" if suggestions else ""}"""
        
        prompt = f"""You are a caring ALS support assistant. The person just said: "{context.user_input}"

Recent conversation:
{history_context}

What you know that might help:
{knowledge_text}

Respond naturally and helpfully. Use {communication_style} language and keep it {response_length}.

Be supportive, share useful information, and help them feel understood. Don't ask questions unless they're really needed."""

        return prompt
    
    def _adapt_response_style(self, response: str, user_preferences: Dict[str, Any], analysis: Dict[str, Any]) -> str:
        """Adapt response style based on learned preferences"""
        if not response:
            return response
        
        # Adjust for communication style
        communication_style = user_preferences.get('communication_style', 'balanced')
        
        if communication_style == 'casual':
            # Make slightly more casual
            response = response.replace('I understand', 'I get it')
            response = response.replace('How are you feeling', 'How are you doing')
        elif communication_style == 'formal':
            # Ensure respectful tone
            response = response.replace('How\'s it going', 'How are you managing')
            response = response.replace('Yeah', 'Yes')
        
        # Adjust for engagement level
        engagement_level = analysis.get('engagement_level', 'normal')
        if engagement_level == 'low':
            # Add encouraging element
            if not any(word in response.lower() for word in ['thank', 'appreciate', 'understand']):
                response = "Thank you for sharing that. " + response
        
        return response
    
    def _generate_enhanced_fallback_response(self, context: ConversationContext) -> str:
        """Enhanced fallback with basic personalization"""
        try:
            # Try to use stored preferences for fallback
            stored_prefs = context.conversation.assessment_state.get('user_preferences', {})
            preferences = stored_prefs.get('preferences', {})
            
            communication_style = preferences.get('communication_style', 'balanced')
            topic_interests = preferences.get('topic_interests', [])
            
            # Customize fallback based on preferences
            if communication_style == 'casual':
                base_response = "I hear you. "
            elif communication_style == 'formal':
                base_response = "I understand what you're sharing with me. "
            else:
                base_response = "Thank you for telling me that. "
            
            # Add interest-based follow-up if available
            if topic_interests:
                if 'emotions' in topic_interests:
                    return base_response + "How are you feeling about everything today?"
                elif 'family' in topic_interests:
                    return base_response + "How are things with your family and support system?"
                elif 'mobility' in topic_interests:
                    return base_response + "How are you managing with getting around?"
            
            # FIXED: Use current dimension/term instead of broken symptom detection
            current_dimension = context.current_dimension or "general health"
            current_term = context.current_term or "your situation"
            
            # Create contextual follow-up based on routing
            if current_dimension != "general health" and current_dimension.lower() != "physiological":
                return base_response + f"How are things going with {current_term}?"
            elif current_dimension.lower() == "physiological":
                return base_response + f"Can you tell me more about how {current_term} has been affecting you?"
            
            return base_response + "What's been most on your mind lately?"
            
        except Exception:
            return self._generate_fallback_response(context)
    
    def _clean_and_validate_response(self, response: str, context: ConversationContext) -> str:
        """Clean and validate LLM response for safety and quality"""
        if not response or len(response.strip()) < 10:
            return self._generate_fallback_response(context)
        
        # Remove any clinical disclaimers or overly formal language
        response = response.strip()
        
        # Ensure response isn't too long (conversation flow)
        sentences = response.split('. ')
        if len(sentences) > 3:
            response = '. '.join(sentences[:3])
            if not response.endswith('.'):
                response += '.'
        
        # Remove any system prompts or meta-commentary that might leak through
        if response.lower().startswith(('as an ai', 'as a language model', 'i cannot', 'i\'m not able to')):
            return self._generate_fallback_response(context)
        
        return response
    
    def _generate_fallback_response(self, context: ConversationContext) -> str:
        """FIXED: Safe fallback response without broken symptom detection dependency"""
        # Use current conversation context instead of broken symptom detection
        current_dimension = context.current_dimension
        current_term = context.current_term
        
        if current_dimension and current_term and current_dimension != "general":
            if current_dimension.lower() == "physiological":
                return f"I understand you're dealing with challenges related to {current_term}. How has this been affecting your daily routine?"
            else:
                return f"Thank you for sharing about {current_term}. How are you managing with this aspect of your life?"
        
        if context.turn_count > 3:
            return "Thank you for sharing that with me. What feels like the most important thing for us to focus on right now?"
        
        return "I hear what you're saying. Can you tell me more about what's been on your mind lately?"
        
    def generate_summary_response(self, context: ConversationContext) -> str:
        """
        Generate detailed summary response after completing term assessments.
        
        STEP 2: RAG-enhanced summary with personalized insights
        """
        try:
            # Analyze completed assessment
            summary_analysis = self._analyze_assessment_completion(context)
            
            # Retrieve relevant support knowledge
            support_knowledge = self._retrieve_support_knowledge(context, summary_analysis)
            
            # Generate comprehensive summary
            summary = self._generate_assessment_summary(context, summary_analysis, support_knowledge)
            
            return summary
            
        except Exception as e:
            log.error(f"Summary generation error: {e}")
            import traceback
            return self._generate_fallback_summary(context)
    
    def _analyze_assessment_completion(self, context: ConversationContext) -> Dict[str, Any]:
        """Analyze completed assessment for summary generation"""
        # Get full conversation history for comprehensive summary
        all_messages = context.conversation.messages if context.conversation.messages else []
        user_responses = [msg.content for msg in all_messages if msg.role == 'user']
        assistant_questions = [msg.content for msg in all_messages if msg.role == 'assistant']

        return {
            'completed_pnm': context.current_dimension,
            'completed_term': context.current_term,
            'user_responses': user_responses,  # All user responses, not just last 3
            'assistant_questions': assistant_questions,  # Include questions asked
            'assessment_length': context.turn_count,
            'key_insights': []
        }
    
    def _retrieve_support_knowledge(self, context: ConversationContext, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Hybrid retrieval + Self-RAG for enhanced knowledge retrieval"""
        try:
            if not (analysis['completed_term'] and analysis['completed_pnm']):
                return []

            # Step 1: Hybrid Retrieval - get from both indexes
            main_query = f"ALS {analysis['completed_pnm']} {analysis['completed_term']} support strategies"

            # Vector search from background knowledge
            bg_results = self.rag.search(main_query, top_k=5, index_kind="background")
            # Vector search from question bank
            q_results = self.rag.search(main_query, top_k=3, index_kind="question")

            # Step 2: Apply hybrid fusion using existing rerank utilities
            fused_results = self._apply_hybrid_fusion(bg_results, q_results)

            # Step 3: Self-RAG - AI judges relevance and refines
            return self._self_rag_filter(fused_results, analysis)

        except Exception as e:
            log.warning(f"Hybrid+Self-RAG retrieval error: {e}")
            # Simple fallback
            query = f"ALS {analysis['completed_pnm']} {analysis['completed_term']} support"
            return self.rag.search(query, top_k=3, index_kind="background")

    def _apply_hybrid_fusion(self, bg_results: list, q_results: list) -> list:
        """Apply hybrid fusion to combine results from different sources"""
        try:
            from app.utils.rerank import hybrid_fusion

            # Treat as lexical vs vector runs for fusion
            lexical_run = bg_results  # background knowledge as "lexical"
            vector_run = q_results    # question bank as "vector"

            return hybrid_fusion(
                lexical_run=lexical_run,
                vector_run=vector_run,
                alpha=0.7,  # Prefer background knowledge slightly
                topn=6
            )
        except Exception:
            # Simple concatenation fallback
            return (bg_results + q_results)[:6]

    def _self_rag_filter(self, results: list, analysis: Dict[str, Any]) -> list:
        """Self-RAG: AI evaluates and filters retrieved knowledge"""
        if not results:
            return []

        try:
            # Build context for AI evaluation
            user_context = ' '.join(analysis.get('user_responses', []))[:300]

            # AI prompt for relevance evaluation
            eval_prompt = f"""You are evaluating knowledge relevance for an ALS assessment summary.

User discussed: {analysis['completed_pnm']} - {analysis['completed_term']}
Key user responses: {user_context}

Rate each piece of knowledge for relevance (1-5, where 5=highly relevant):

"""

            # Add each knowledge piece for evaluation
            for i, result in enumerate(results[:4]):  # Limit to avoid long prompts
                text = result.get('text', '')[:200]
                eval_prompt += f"{i+1}. {text}...\n"

            eval_prompt += "\nReturn only numbers (e.g., '4 3 5 2') for each knowledge piece:"

            # Get AI evaluation
            ai_response = self.llm.generate_text(eval_prompt).strip()

            # Parse scores and filter
            try:
                scores = [int(x) for x in ai_response.split() if x.isdigit()]
                filtered_results = []

                for i, score in enumerate(scores):
                    if i < len(results) and score >= 3:  # Keep if score >= 3
                        filtered_results.append(results[i])

                return filtered_results[:4] if filtered_results else results[:3]

            except (ValueError, IndexError):
                # Fallback if AI parsing fails
                return results[:3]

        except Exception as e:
            log.warning(f"Self-RAG filtering error: {e}")
            return results[:3]

    def _retrieve_uc1_support_knowledge(self, pnm: str, term: str, avg_score: float, user_responses: List[str]) -> List[Dict[str, Any]]:
        """UC1-specific Hybrid retrieval + Self-RAG for scored assessment knowledge"""
        try:
            # Step 1: Hybrid Retrieval - get from both indexes
            # Include score context for more targeted retrieval
            score_context = "low difficulty" if avg_score <= 2 else "moderate difficulty" if avg_score <= 4 else "high difficulty"
            main_query = f"ALS {pnm} {term} {score_context} management support strategies"

            # Vector search from background knowledge
            bg_results = self.rag.search(main_query, top_k=5, index_kind="background")
            # Vector search from question bank
            q_results = self.rag.search(main_query, top_k=3, index_kind="question")

            # Step 2: Apply hybrid fusion using existing rerank utilities
            fused_results = self._apply_hybrid_fusion(bg_results, q_results)

            # Step 3: Self-RAG - AI judges relevance based on UC1 scored responses
            return self._self_rag_filter_uc1(fused_results, pnm, term, avg_score, user_responses)

        except Exception as e:
            log.warning(f"UC1 Hybrid+Self-RAG retrieval error: {e}")
            # Simple fallback
            query = f"ALS {pnm} {term} support"
            return self.rag.search(query, top_k=3, index_kind="background")

    def _self_rag_filter_uc1(self, results: list, pnm: str, term: str, avg_score: float, user_responses: List[str]) -> list:
        """UC1-specific Self-RAG: AI evaluates knowledge based on scored responses"""
        if not results:
            return []

        try:
            # Build UC1-specific context for AI evaluation
            user_context = ' '.join(user_responses)[:300]
            score_interpretation = "lower functioning" if avg_score >= 5 else "moderate functioning" if avg_score >= 3 else "higher functioning"

            # AI prompt for UC1 relevance evaluation
            eval_prompt = f"""You are evaluating knowledge relevance for an ALS {pnm} assessment summary.

Assessment: {term} with average score {avg_score:.1f}/7 ({score_interpretation})
Key user responses: {user_context}

Rate each piece of knowledge for relevance (1-5, where 5=highly relevant for this specific score level and responses):

"""

            # Add each knowledge piece for evaluation
            for i, result in enumerate(results[:4]):  # Limit to avoid long prompts
                text = result.get('text', '')[:200]
                eval_prompt += f"{i+1}. {text}...\n"

            eval_prompt += "\nReturn only numbers (e.g., '4 3 5 2') for each knowledge piece:"

            # Get AI evaluation
            ai_response = self.llm.generate_text(eval_prompt).strip()

            # Parse scores and filter
            try:
                scores = [int(x) for x in ai_response.split() if x.isdigit()]
                filtered_results = []

                for i, score in enumerate(scores):
                    if i < len(results) and score >= 3:  # Keep if score >= 3
                        filtered_results.append(results[i])

                return filtered_results[:4] if filtered_results else results[:3]

            except (ValueError, IndexError):
                # Fallback if AI parsing fails
                return results[:3]

        except Exception as e:
            log.warning(f"UC1 Self-RAG filtering error: {e}")
            return results[:3]

    def _generate_assessment_summary(self, context: ConversationContext, analysis: Dict[str, Any], knowledge: List[Dict[str, Any]]) -> str:
        """Generate comprehensive assessment summary using LLM"""
        try:
            # Build summary prompt - ensure meaningful knowledge content
            if knowledge:
                knowledge_text = "\n".join([
                    f"- {doc.get('text', '')[:150]}" for doc in knowledge if doc.get('text', '').strip()
                ])
            else:
                knowledge_text = ""

            # If no knowledge retrieved, provide basic ALS support guidance
            if not knowledge_text.strip():
                dimension = analysis['completed_pnm']
                term = analysis['completed_term']
                knowledge_text = f"""- Regular monitoring and adaptation of strategies is important for {dimension} concerns
- Professional healthcare team consultation can provide personalized guidance for {term}
- Support groups and peer connections offer valuable shared experiences and coping strategies
- Assistive technologies and adaptive equipment may help maintain independence and quality of life"""
            
            # Build conversation context with both questions and responses
            conversation_context = []
            user_responses = analysis.get('user_responses', [])
            assistant_questions = analysis.get('assistant_questions', [])

            # Create interleaved conversation flow for better context
            max_length = max(len(user_responses), len(assistant_questions))
            for i in range(max_length):
                if i < len(assistant_questions):
                    conversation_context.append(f"Question: {assistant_questions[i][:200]}...")
                if i < len(user_responses):
                    conversation_context.append(f"Their response: {user_responses[i]}")

            conversation_summary = "\n".join(conversation_context[-10:])  # Last 10 exchanges

            prompt = f"""Based on your {analysis['completed_pnm']} assessment conversation about {analysis['completed_term']}, here's what we discussed:

{conversation_summary}

Professional support resources:
{knowledge_text}

Provide a professional assessment summary speaking directly to the person. Use proper line breaks and formatting:

## Assessment Overview:
Briefly summarize your current situation with {analysis['completed_term']}.

## Key Findings:
 Identify 2-3 specific areas where you're managing well
 Highlight 2-3 areas that may need attention or support

## Personalized Recommendations:
 Provide specific, actionable strategies based on your responses
 Reference appropriate support resources or interventions
 Consider your individual circumstances and preferences

## Next Steps:
Suggest concrete actions you can take to improve your situation.

IMPORTANT:
- Use second person (you, your) throughout - speak directly to the person
- Include proper line breaks between sections
- Be specific about their actual responses rather than generic
- Make each point targeted to what they actually shared
- Use caring but professional tone"""

            return self.llm.generate_text(prompt)
            
        except Exception as e:
            log.error(f"Summary LLM generation error: {e}")
            import traceback
            return self._generate_fallback_summary(context)
    
    def _generate_fallback_summary(self, context: ConversationContext) -> str:
        """Generate fallback summary when LLM fails"""
        pnm = context.current_dimension or "your needs"
        return f"Thank you for sharing your experiences about {pnm}. Your openness helps me better understand your situation. Based on what you've told me, I can see you're navigating some important challenges. Let's continue exploring how we can best support you in this area."
        
    def generate_info_cards(self, context: ConversationContext) -> List[Dict[str, Any]]:
        """
        Generate contextual information cards using EnhancedInfoProvider.
        
        STEP 3: Enhanced info provider integration with intelligent decision making
        """
        try:
            # FIXED: Create info context without broken symptom detection
            # Extract keywords from recent user messages instead
            severity_indicators = []
            if context.user_input:
                # Use simple keyword extraction as severity indicators
                keywords = [word.lower() for word in context.user_input.split() if len(word) > 3]
                severity_indicators = keywords[:3]  # Limit to first 3 meaningful words
            
            info_context = InfoContext(
                current_pnm=context.current_dimension or "Physiological",
                current_term=context.current_term or "general",
                last_answer=context.user_input,
                question_history=[msg.content for msg in context.conversation.messages[-3:] if msg.role == 'user'],
                severity_indicators=severity_indicators
            )
            
            # Use enhanced info provider for intelligent card generation
            info_cards = self.info_provider.get_contextual_info_cards(info_context)
            
            if info_cards:
                log.info(f"EnhancedInfoProvider generated {len(info_cards)} cards")
                return info_cards
            
            # Fallback to basic RAG-based generation if enhanced provider fails
            return self._generate_basic_info_cards(context)
            
        except Exception as e:
            log.error(f"Enhanced info card generation error: {e}")
            # Fallback to basic generation
            return self._generate_basic_info_cards(context)
    
    def _generate_basic_info_cards(self, context: ConversationContext) -> List[Dict[str, Any]]:
        """Fallback basic info card generation using RAG"""
        try:
            if not context.detected_symptoms and not context.current_dimension:
                return []
            
            # Determine focus for info cards
            focus_topic = None
            if context.current_dimension and context.current_term:
                focus_topic = f"{context.current_dimension} {context.current_term}"
            elif context.detected_symptoms:
                focus_topic = context.detected_symptoms[0]
            
            if not focus_topic:
                return []
            
            # Retrieve information with caching
            info_query = f"ALS {focus_topic} practical tips daily living support"
            
            # Direct RAG search (removed caching for simplicity)
            info_docs = self.rag.search(info_query, top_k=3, index_kind="background")
            
            if not info_docs:
                return []
            
            # Generate info card
            card_content = self._format_info_card(focus_topic, info_docs)
            
            return [card_content] if card_content else []
            
        except Exception as e:
            log.error(f"Basic info card generation error: {e}")
            return []
    
    def _format_info_card(self, topic: str, docs: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Format RAG results into info card structure"""
        try:
            # Extract key points from RAG docs
            bullets = []
            for doc in docs[:3]:
                text = doc.get('text', '')
                if len(text) > 50:
                    # Simple bullet point extraction (can be enhanced)
                    bullet = text[:120] + "..." if len(text) > 120 else text
                    bullets.append(bullet)
            
            if bullets:
                return {
                    "title": f"Support Information: {topic.title()}",
                    "bullets": bullets[:3],  # Limit to 3 bullets
                    "source": "Knowledge Base"
                }
        except Exception as e:
            log.error(f"Info card formatting error: {e}")
        
        return None


# INTEGRATION HELPER FUNCTIONS

def create_conversation_context(
    conversation: ConversationDocument,
    user_input: str,
    ai_router: AIRouter
) -> ConversationContext:
    """
    Factory function to create ConversationContext from current conversation state.
    
    This function bridges the existing DocumentStorage system with the new
    enhanced dialogue framework.
    """
    # Extract current state with proper None handling
    mode_str = conversation.assessment_state.get('dialogue_mode', 'free_dialogue')
    if mode_str and mode_str in [m.value for m in ConversationMode]:
        mode = ConversationMode(mode_str)
    else:
        mode = ConversationMode.FREE_DIALOGUE
    
    # Count user messages for turn tracking
    turn_count = sum(1 for msg in conversation.messages if msg.role == 'user')

    # Debug: Log conversation state for new conversations
    if turn_count == 1:  # First user message in this conversation
        pass  # Debug print removed

    # Skip automatic symptom detection during free dialogue
    # Keywords should only be used for question bank retrieval, not symptom detection
    # This aligns with original design: AI-expanded keywords for question matching
    detected_symptoms = []
    
    return ConversationContext(
        conversation=conversation,
        user_input=user_input,
        mode=mode,
        turn_count=turn_count,
        detected_symptoms=detected_symptoms,
        current_dimension=conversation.dimension,
        current_term=conversation.assessment_state.get('current_term'),
        recent_scores=[]
    )


def convert_to_conversation_response(dialogue_response: DialogueResponse) -> Dict[str, Any]:
    """
    Convert DialogueResponse to the format expected by chat_unified.py.
    
    This ensures compatibility with the existing API response structure.
    """
    response_data = {
        "question_text": dialogue_response.content,
        "question_type": ("dialogue" if dialogue_response.response_type == ResponseType.CHAT
                         else "assessment" if dialogue_response.response_type == ResponseType.QUESTION
                         else "summary"),
        "options": dialogue_response.options or [],
        "allow_text_input": True,
        "dialogue_mode": dialogue_response.mode == ConversationMode.FREE_DIALOGUE,
        "should_continue_dialogue": dialogue_response.should_continue_dialogue
    }
    
    # Add assessment data if present
    if dialogue_response.current_pnm:
        response_data["current_pnm"] = dialogue_response.current_pnm
    if dialogue_response.current_term:
        response_data["current_term"] = dialogue_response.current_term
    if dialogue_response.question_id:
        response_data["question_id"] = dialogue_response.question_id
    
    # Add metadata
    if dialogue_response.detected_symptoms:
        response_data["detected_symptoms"] = dialogue_response.detected_symptoms
    if dialogue_response.info_cards:
        response_data["info_cards"] = dialogue_response.info_cards

    return response_data


# Add missing method to ResponseGenerator class
def _get_conversation_history_for_response_generator(self, context: 'ConversationContext', num_turns: int = 3) -> str:
    """Get recent conversation history for context"""
    try:
        messages = context.conversation.messages[-num_turns*2:] if context.conversation.messages else []
        history = []

        for msg in messages:
            role = "Patient" if msg.role == 'user' else "Assistant"
            history.append(f"{role}: {msg.content}")

        return '\n'.join(history)
    except Exception:
        return "No conversation history available"

# Monkey patch the method into ResponseGenerator class
ResponseGenerator._get_conversation_history = _get_conversation_history_for_response_generator


class FreeDialogueMode:
    """
    Free dialogue conversation mode with RAG+LLM integration.
    
    STEP 2: Full implementation with intelligent conversation flow
    """
    
    def __init__(self, qb: QuestionBank, ai_router: AIRouter):
        self.qb = qb
        self.ai_router = ai_router
        self.response_generator = ResponseGenerator()
        self.transition_detector = TransitionDetector(RAGQueryClient(), LLMClient())
        
    def process_dialogue(self, context: ConversationContext) -> DialogueResponse:
        """
        Process free dialogue with intelligent conversation management.
        
        Flow: Analyze input  Generate response  Check transition  Return
        """
        try:
            # Generate intelligent conversational response
            response_content = self.response_generator.generate_chat_response(context)
            
            # Generate contextual info cards
            info_cards = self.response_generator.generate_info_cards(context)
            
            # Check if should transition to assessment mode
            should_transition = self.transition_detector.should_start_assessment(context)
            next_mode = ConversationMode.DIMENSION_ANALYSIS if should_transition else None
            
            # Determine appropriate PNM/term for potential transition
            suggested_pnm, suggested_term = self._suggest_assessment_focus(context)
            
            return DialogueResponse(
                content=response_content,
                response_type=ResponseType.CHAT,
                mode=ConversationMode.FREE_DIALOGUE,
                should_continue_dialogue=not should_transition,
                next_mode=next_mode,
                current_pnm=suggested_pnm,
                current_term=suggested_term,
                info_cards=info_cards,
                detected_symptoms=context.detected_symptoms,
                confidence_score=0.8  # High confidence in RAG+LLM responses
            )
            
        except Exception as e:
            log.error(f"Free dialogue processing error: {e}")
            return self._fallback_free_dialogue(context)
    
    def _suggest_assessment_focus(self, context: ConversationContext) -> tuple[Optional[str], Optional[str]]:
        """Suggest PNM dimension and term based on conversation context"""
        # If symptoms detected, map to appropriate PNM
        if context.detected_symptoms:
            primary_symptom = context.detected_symptoms[0]
            
            # Map symptoms to PNM dimensions using ai_router knowledge
            symptom_to_pnm = {
                'breathing': ('Physiological', 'Breathing exercises'),
                'swallowing': ('Physiological', 'Nutrition management'),
                'mobility': ('Physiological', 'Mobility and transfers'),
                'speaking': ('Love & Belonging', 'Communication with support network'),
                'emotional': ('Esteem', 'Emotional wellbeing'),
                'fatigue': ('Physiological', 'Energy conservation')
            }
            
            return symptom_to_pnm.get(primary_symptom, ('Safety', 'Emergency preparedness'))
        
        # Default progression through PNM hierarchy
        return ('Safety', 'Emergency preparedness')
    
    def _fallback_free_dialogue(self, context: ConversationContext) -> DialogueResponse:
        """Fallback for free dialogue processing"""
        return DialogueResponse(
            content="I understand what you're sharing with me. What would be most helpful to discuss right now?",
            response_type=ResponseType.CHAT,
            mode=ConversationMode.FREE_DIALOGUE,
            should_continue_dialogue=True,
            detected_symptoms=context.detected_symptoms
        )


class DimensionAnalysisMode:
    """
    Dimension analysis mode with high-density Q&A and intelligent summaries.
    
    STEP 2: Full implementation with RAG-powered assessment and scoring
    """
    
    def __init__(self, qb: QuestionBank, ai_router: AIRouter, scoring_engine: PNMScoringEngine):
        self.qb = qb
        self.ai_router = ai_router
        self.scoring_engine = scoring_engine
        self.ai_scorer = AIFreeTextScorer(ai_router)  # Add missing ai_scorer
        self.response_generator = ResponseGenerator()  # Add for RAG AI summaries
        # Simplified initialization - only use core components that exist
        
    async def process_assessment(self, context: ConversationContext) -> DialogueResponse:
        """
        Process dimension analysis with intelligent question selection and scoring.

        Flow:
        1. Process user response if provided (score it)
        2. Check completion  Generate question/summary  Update state  Return
        """
        try:
            # STEP 1: Process user response if provided (score and record it)
            if context.user_input.strip():
                await self._process_assessment_response(context)

            # STEP 2: Check if current term assessment is complete
            if self._is_term_complete(context):
                summary_response = self._generate_term_summary(context)
                return summary_response

            # STEP 3: Generate next assessment question
            return self._generate_assessment_question(context)

        except Exception as e:
            log.error(f"Dimension analysis processing error: {e}")
            # Return a working fallback instead of calling undefined method
            return DialogueResponse(
                content="How are you managing with your current condition?",
                response_type=ResponseType.CHAT,
                mode=ConversationMode.DIMENSION_ANALYSIS,
                should_continue_dialogue=True,
                current_pnm="Physiological",
                current_term="General health"
            )

    async def _process_assessment_response(self, context: ConversationContext):
        """Process user's assessment response and record it"""
        try:
            # Get current question context from assessment state
            question_context = context.conversation.assessment_state.get('question_context', {})
            current_question_id = question_context.get('question_id')

            if current_question_id:
                # Mark this question as asked to avoid repetition
                asked_questions = context.conversation.assessment_state.get('asked_questions', [])
                if current_question_id not in asked_questions:
                    asked_questions.append(current_question_id)
                    context.conversation.assessment_state['asked_questions'] = asked_questions

                # Score the response using the existing scoring engine
                pnm = context.current_dimension or 'Physiological'
                term = context.current_term or 'General'

                # Try to get score from option first, then use AI scoring
                score = self._extract_option_score(context.user_input, question_context)
                if score is None:
                    # Use AI scoring for free text response
                    ai_score_result = await self.ai_scorer.score_free_text_response(
                        context.user_input,
                        question_context,
                        pnm,
                        context.conversation.messages[-5:]  # Recent context
                    )
                    score = ai_score_result.score
                else:
                    pass  # Debug print removed

                # Store score in conversation state for term completion analysis
                term_key = f"{pnm}_{term}"

                if 'temp_term_scores' not in context.conversation.assessment_state:
                    context.conversation.assessment_state['temp_term_scores'] = {}

                if term_key not in context.conversation.assessment_state['temp_term_scores']:
                    context.conversation.assessment_state['temp_term_scores'][term_key] = []

                # Add score entry with metadata
                score_entry = {
                    'question_id': current_question_id,
                    'score': score,
                    'user_response': context.user_input,
                    'timestamp': context.conversation.messages[-1].timestamp if context.conversation.messages else None
                }
                context.conversation.assessment_state['temp_term_scores'][term_key].append(score_entry)


        except Exception as e:
            log.error(f"Error processing assessment response: {e}")

    def _extract_option_score(self, user_input: str, question_context: dict) -> float:
        """Extract score from option selection"""
        try:
            options = question_context.get('options', [])
            if not options:
                return None

            # Try to match user input to option value or label
            for opt in options:
                option_value = str(opt.get('value', ''))
                option_label = str(opt.get('label', ''))

                if (user_input.strip().lower() == option_value.lower() or
                    user_input.strip().lower() == option_label.lower()):
                    score_value = opt.get('score')
                    if score_value is not None:
                        return float(score_value)  # Use actual option score
                    return None  # No score available for this option

            return None
        except Exception:
            return None

    def _is_term_complete(self, context: ConversationContext) -> bool:
        """Determine if current term assessment is complete based on collected scores"""
        if not context.current_term:
            return False

        # Check if we have enough valid scores for this term (not just questions)
        current_pnm = context.current_dimension or "Physiological"
        current_term = context.current_term or "General health"
        term_key = f"{current_pnm}_{current_term}"

        temp_scores = context.conversation.assessment_state.get('temp_term_scores', {})
        valid_scores = []

        if term_key in temp_scores:
            valid_scores = [entry['score'] for entry in temp_scores[term_key] if entry['score'] is not None]

        # UC1 flexible completion: Complete after 2 valid scores (user feedback: more flexible)
        # This allows faster completion for single-term assessment
        is_complete = len(valid_scores) >= 2


        if is_complete:
            # Calculate term average score when complete
            self._finalize_term_score(context)

        return is_complete

    def _finalize_term_score(self, context: ConversationContext):
        """Calculate and store final term average score"""
        try:
            current_pnm = context.current_dimension or "Physiological"
            current_term = context.current_term or "General health"
            term_key = f"{current_pnm}_{current_term}"

            temp_scores = context.conversation.assessment_state.get('temp_term_scores', {})
            if term_key in temp_scores and len(temp_scores[term_key]) > 0:
                # Calculate average score for this term using only valid scores
                individual_scores = [entry['score'] for entry in temp_scores[term_key] if entry['score'] is not None]

                if len(individual_scores) > 0:
                    average_score = sum(individual_scores) / len(individual_scores)
                    log.info(f"[TERM_COMPLETE] Term {term_key} complete with {len(individual_scores)} valid scores (out of {len(temp_scores[term_key])} total questions), average score: {average_score:.2f}")
                else:
                    log.warning(f"[TERM_COMPLETE] Term {term_key} has no valid scores - skipping term score storage")
                    return  # Don't store anything if no valid scores

                # Store final term score using existing storage mechanism
                # This will integrate with existing storage and database systems
                if hasattr(self, 'storage') and hasattr(self.storage, 'add_score'):
                    self.storage.add_score(
                        context.conversation.id,
                        current_pnm,
                        current_term,
                        average_score,
                        scoring_method='term_average',
                        individual_scores=individual_scores,
                        total_questions=len(individual_scores)
                    )
                else:
                    pass  # Debug print removed

                # Clean up temporary scores for this term
                del temp_scores[term_key]
                log.info(f"[TERM_COMPLETE] Stored average score {average_score:.2f} for {current_pnm}/{current_term}")

        except Exception as e:
            log.error(f"Error finalizing term score: {e}")



    def _generate_assessment_question(self, context: ConversationContext) -> DialogueResponse:
        """Generate next assessment question for current dimension/term"""
        try:
            pnm = context.current_dimension or 'Safety'
            term = context.current_term or 'Emergency preparedness'
            
            # Get asked question IDs to avoid repetition
            asked_qids = context.conversation.assessment_state.get('asked_questions', [])
            
            # Choose next question using question bank
            question_item = self.qb.choose_for_term(pnm, term, asked_qids)
            
            if not question_item:
                # No more questions for this term, trigger completion
                return self._generate_term_summary(context)
            
            # Prepare question options
            options = []
            if question_item.options:
                options = [
                    {
                        'value': opt.get('id', opt.get('value', str(i))),
                        'label': opt.get('label', opt.get('text', str(opt)))
                    }
                    for i, opt in enumerate(question_item.options)
                ]
            
            # Store question context for AI scoring
            question_context = {
                'question': question_item.main,
                'text': question_item.main,  # fallback for compatibility
                'options': question_item.options,  # Original options with scores
                'question_id': question_item.id,
                'pnm': pnm,
                'term': term
            }

            # Update assessment state with question context
            if not hasattr(context.conversation, 'assessment_state'):
                context.conversation.assessment_state = {}
            context.conversation.assessment_state['question_context'] = question_context

            return DialogueResponse(
                content=question_item.main,
                response_type=ResponseType.CHAT,
                mode=ConversationMode.DIMENSION_ANALYSIS,
                current_pnm=pnm,
                current_term=term,
                question_id=question_item.id,
                options=options,
                should_continue_dialogue=True,
                confidence_score=0.9  # High confidence in structured questions
            )
            
        except Exception as e:
            log.error(f"Assessment question generation error: {e}")
            return self._fallback_dimension_analysis(context)
    
    def _generate_term_summary(self, context: ConversationContext) -> DialogueResponse:
        """Generate comprehensive term completion summary using RAG AI and lock conversation"""
        try:
            # Use RAG-enhanced professional summary generation
            summary_content = self.response_generator.generate_summary_response(context)
        except Exception as e:
            # Intelligent fallback without hardcoded templates
            pnm = context.current_dimension or 'Safety'
            term = context.current_term or 'Assessment'
            summary_content = f"Assessment complete for {term} in {pnm}. Your responses provide valuable insights that will guide personalized support recommendations. This conversation is now complete."

        # Mark conversation as completed (UC1 requirement: chat)
        if hasattr(context.conversation, 'status'):
            context.conversation.status = "completed"

        return DialogueResponse(
            content=summary_content,
            response_type=ResponseType.SUMMARY,
            mode=ConversationMode.DIMENSION_ANALYSIS,  # Keep in assessment mode to prevent further input
            current_pnm=pnm,
            current_term=term,
            should_continue_dialogue=False  # Lock conversation - no further dialogue
        )
    
    def _determine_next_assessment_focus(self, context: ConversationContext) -> tuple[Optional[str], Optional[str]]:
        """
        Determine next PNM dimension and term using reliable database-driven routing.
        Replaces unreliable AI/keyword routing with direct database decisions.
        """
        user_id = context.conversation.user_id
        
        try:
            # Use reliable routing engine for database-driven decisions
            routing_decision = self.reliable_router.get_reliable_route(
                user_id, 
                context={'current_dimension': context.current_dimension}
            )
            
            next_pnm = routing_decision.get('pnm_dimension')
            next_term = routing_decision.get('term')
            
            # Record successful routing for optimization
            if next_pnm and next_term:
                self.reliable_router.record_routing_success(user_id, routing_decision)
                
                self.log.info(f"Reliable routing: {user_id} -> {next_pnm} / {next_term} "
                            f"(method: {routing_decision.get('routing_method', 'unknown')})")
                
                return next_pnm, next_term
        
        except Exception as e:
            self.log.error(f"Reliable routing failed: {e}")
        
        # Fallback to original progression logic
        current_pnm = context.current_dimension
        
        # PNM progression order (simplified)
        pnm_progression = [
            'Physiological',
            'Safety', 
            'Love & Belonging',
            'Esteem',
            'Self-Actualisation',
            'Cognitive',
            'Aesthetic',
            'Transcendence'
        ]
        
        # Default terms for each PNM (using ai_router knowledge)
        pnm_default_terms = {
            'Physiological': 'Breathing exercises',
            'Safety': 'Emergency preparedness',
            'Love & Belonging': 'Communication with support network',
            'Esteem': 'Home adaptations implementation',
            'Self-Actualisation': 'Gaming with adaptive devices',
            'Cognitive': 'Emergency preparedness',
            'Aesthetic': 'Gaming with adaptive devices',
            'Transcendence': 'Communication with support network'
        }
        
        # Find next PNM in progression
        if current_pnm in pnm_progression:
            current_index = pnm_progression.index(current_pnm)
            if current_index < len(pnm_progression) - 1:
                next_pnm = pnm_progression[current_index + 1]
                next_term = pnm_default_terms.get(next_pnm, 'General assessment')
                return next_pnm, next_term
        
        # If at end of progression, cycle back or end
        return None, None
    
    async def score_user_response(
        self, 
        user_response: str, 
        context: ConversationContext,
        question_context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        Enhanced scoring for user responses using AI and traditional methods
        """
        try:
            current_pnm = context.current_dimension or "General"
            
            # Check if response is free-text or structured
            if question_context and 'options' in question_context:
                # Structured question - use built-in scores
                selected_option = self._match_response_to_option(user_response, question_context['options'])
                if selected_option:
                    score_value = selected_option.get('score')
                    if score_value is not None:
                        return {
                            'score': score_value,
                            'qol_impact': selected_option.get('qol_impact', '50% quality of life'),
                            'scoring_method': 'structured_option',
                            'confidence': 0.9
                        }
                    # No score available for this option, skip scoring
            
            # Free-text response - use AI scoring
            ai_score_result = await self.ai_scorer.score_free_text_response(
                user_response, 
                question_context or {}, 
                current_pnm,
                context.conversation.messages[-5:]  # Recent context
            )
            
            return {
                'score': ai_score_result.score,
                'qol_impact': ai_score_result.quality_of_life_impact,
                'scoring_method': 'ai_powered',
                'confidence': ai_score_result.confidence,
                'reasoning': ai_score_result.reasoning,
                'insights': ai_score_result.extracted_insights
            }
            
        except Exception as e:
            self.log.error(f"Enhanced scoring failed: {e}")
            # Fallback to traditional scoring
            traditional_score = self.scoring_engine.score_response(
                user_response, current_pnm, "general"
            )
            return {
                'score': traditional_score.total_score / 4,  # Convert to 0-7 scale
                'qol_impact': f"{traditional_score.percentage}% functionality",
                'scoring_method': 'traditional_fallback',
                'confidence': 0.6
            }
    
    def _match_response_to_option(
        self, 
        user_response: str, 
        options: List[Dict[str, Any]]
    ) -> Optional[Dict[str, Any]]:
        """Match user response to structured question option"""
        response_lower = user_response.lower()
        
        # Try exact label matching first
        for option in options:
            label = option.get('label', '').lower()
            if label in response_lower or response_lower in label:
                return option
        
        # Try ID matching
        for option in options:
            option_id = option.get('id', '').lower()
            if option_id in response_lower:
                return option
        
        # Keyword matching for common responses
        keyword_mapping = {
            'not prepared': lambda opt: 'none' in opt.get('id', '') or 'not prepared' in opt.get('label', '').lower(),
            'somewhat': lambda opt: 'draft' in opt.get('id', '') or 'partial' in opt.get('label', '').lower(),
            'ready': lambda opt: 'ready' in opt.get('id', '') or 'prepared' in opt.get('label', '').lower(),
            'fully': lambda opt: 'drill' in opt.get('id', '') or 'fully' in opt.get('label', '').lower()
        }
        
        for keyword, matcher in keyword_mapping.items():
            if keyword in response_lower:
                matching_options = [opt for opt in options if matcher(opt)]
                if matching_options:
                    return matching_options[0]
        
        return None
    
    def calculate_comprehensive_pnm_scores(self, context: ConversationContext) -> Dict[str, Any]:
        """
        Calculate comprehensive PNM scores with missing value handling
        """
        try:
            # Extract all scores from conversation
            conversation_scores = []
            responses_data = {}
            
            # Process conversation for scoring data
            for msg in context.conversation.messages:
                if hasattr(msg, 'metadata') and msg.metadata:
                    score_data = msg.metadata.get('score_data')
                    if score_data:
                        # Convert to PNMScore if needed
                        if isinstance(score_data, dict):
                            pnm_score = self._dict_to_pnm_score(score_data)
                            if pnm_score:
                                conversation_scores.append(pnm_score)
                
                # Collect response data for analysis
                if msg.role == 'user':
                    responses_data[msg.timestamp or len(responses_data)] = {
                        'content': msg.content,
                        'context': getattr(msg, 'context', {})
                    }
            
            # Use enhanced PNM scorer for comprehensive calculation
            comprehensive_profile = self.enhanced_pnm_scorer.calculate_pnm_scores_with_missing_values(
                responses_data, conversation_scores
            )
            
            # Add stage scoring
            stage_scores = self.stage_scorer.calculate_stage_scores(comprehensive_profile)
            comprehensive_profile['stage_analysis'] = stage_scores
            
            # Store results directly in user profile for reliable routing
            user_id = context.conversation.user_id
            self.profile_manager.store_comprehensive_assessment_results(
                user_id, comprehensive_profile, stage_scores
            )
            
            self.log.info(f"Assessment results stored in user profile: {user_id}")
            
            return comprehensive_profile
            
        except Exception as e:
            self.log.error(f"Comprehensive PNM scoring failed: {e}")
            return {}
    
    def _dict_to_pnm_score(self, score_dict: Dict[str, Any]) -> Optional[Any]:
        """Convert score dictionary to PNMScore object"""
        try:
            from app.services.pnm_scoring import PNMScore
            required_fields = ['pnm_level', 'domain', 'awareness_score', 'understanding_score', 'coping_score', 'action_score']
            
            if all(field in score_dict for field in required_fields):
                return PNMScore(
                    pnm_level=score_dict['pnm_level'],
                    domain=score_dict['domain'],
                    awareness_score=score_dict['awareness_score'],
                    understanding_score=score_dict['understanding_score'],
                    coping_score=score_dict['coping_score'],
                    action_score=score_dict['action_score']
                )
        except Exception as e:
            self.log.warning(f"Failed to convert dict to PNMScore: {e}")
        return None
    
    def _fallback_dimension_analysis(self, context: ConversationContext) -> DialogueResponse:
        """Fallback for dimension analysis processing"""
        return DialogueResponse(
            content="Let's continue with your assessment. How would you describe your current situation?",
            response_type=ResponseType.CHAT,
            mode=ConversationMode.DIMENSION_ANALYSIS,
            should_continue_dialogue=True
        )
    
    def _fallback_summary(self, context: ConversationContext) -> DialogueResponse:
        """Fallback for summary generation"""
        pnm = context.current_dimension or "this area"
        return DialogueResponse(
            content=f"Thank you for sharing your experiences with {pnm}. Your insights help me understand your needs better. Let's continue exploring how we can support you.",
            response_type=ResponseType.SUMMARY,
            mode=ConversationMode.DIMENSION_ANALYSIS,
            should_continue_dialogue=True
        )





class UseCaseOneManager:
    """
    Use Case 1: General conversation mode manager.

    Handles: free dialogue  diagonal trigger  structured assessment  summary
    """

    def __init__(self, qb: QuestionBank, ai_router: AIRouter, main_manager=None):
        self.qb = qb
        self.question_bank = qb  # Alias for compatibility
        self.ai_router = ai_router
        self.main_manager = main_manager  # Access to storage through main manager
        # Access LLM and storage through main manager
        self.llm = getattr(main_manager, 'llm', None) if main_manager else None
        self.storage = main_manager.storage if main_manager else None
        self.ai_scorer = AIFreeTextScorer()  # Add ai_scorer for UC1 - uses IBM WatsonX directly
        self.response_generator = ResponseGenerator()
        self.transition_detector = TransitionDetector(RAGQueryClient(), LLMClient())

    async def handle_conversation_flow(self, context: ConversationContext) -> DialogueResponse:
        """Handle complete Use Case 1 flow"""

        # Phase 1: Free Dialogue (Turns 1-3) - Allow diagonal trigger earlier
        if context.turn_count <= 3:

            # Check for explicit assessment request even in early turns
            if await self._should_trigger_assessment(context):
                return await self._handle_assessment_phase(context)

            return await self._handle_free_dialogue_phase(context)

        # Phase 2: Diagonal Trigger Check (Turn 4+)
        if await self._should_trigger_assessment(context):
            return await self._handle_assessment_phase(context)

        # Continue dialogue if assessment not triggered
        return await self._handle_free_dialogue_phase(context)

    async def _handle_free_dialogue_phase(self, context: ConversationContext) -> DialogueResponse:
        """Pure dialogue phase - AI intelligent response, no questions"""
        try:
            # Generate AI response for dialogue
            content = self.response_generator.generate_chat_response(context)

            # AI dialogue response storage is handled by chat_unified.py centralized storage

            return DialogueResponse(
                content=content,
                response_type=ResponseType.CHAT,
                mode=ConversationMode.FREE_DIALOGUE,
                should_continue_dialogue=True,
                current_pnm=None,
                current_term=None
            )
        except Exception as e:
            log.error(f"Free dialogue error: {e}")
            fallback_content = "I'm here to listen and help. What would you like to talk about?"

            # AI fallback dialogue response storage is handled by chat_unified.py centralized storage

            return DialogueResponse(
                content=fallback_content,
                response_type=ResponseType.CHAT,
                mode=ConversationMode.FREE_DIALOGUE,
                should_continue_dialogue=True
            )

    async def _ai_analyze_symptoms_and_readiness(self, context: ConversationContext) -> dict:
        """Use AI to analyze user symptoms and assess readiness for evaluation"""
        try:
            # Get conversation history
            recent_messages = [msg.content for msg in context.conversation.messages[-5:] if msg.role == 'user']
            conversation_text = " ".join(recent_messages)

            prompt = f"""Analyze this ALS patient conversation to determine:
1. Symptoms mentioned and their severity
2. Readiness for structured assessment
3. Most relevant PNM dimensions and terms

Conversation: "{conversation_text}"
Current message: "{context.user_input}"

Available PNM dimensions:
- Physiological: breathing, swallowing, mobility, sleep, nutrition
- Safety: accessibility, equipment, technology, decision-making
- Love & Belonging: relationships, social activities, communication
- Esteem: independence, dignity, accomplishment, contribution
- Self-Actualisation: purpose, meaning, personal growth
- Cognitive: memory, problem-solving, information processing
- Aesthetic: beauty, creativity, environmental enjoyment
- Transcendence: spirituality, legacy, connection to larger purpose

Respond with JSON:
{{
    "symptoms_detected": ["symptom1", "symptom2"],
    "symptom_count": number,
    "severity_level": "mild|moderate|severe",
    "ready_for_assessment": boolean,
    "readiness_reason": "explanation",
    "suggested_pnm": "most relevant dimension",
    "suggested_term": "most relevant specific term",
    "confidence": 0.0-1.0
}}"""

            response = self.llm.generate_text(prompt)

            try:
                import json
                analysis = json.loads(response)
                return analysis
            except:
                # Fallback if JSON parsing fails
                return {
                    "symptoms_detected": [],
                    "symptom_count": 0,
                    "ready_for_assessment": context.turn_count >= 4,
                    "suggested_pnm": "Physiological",
                    "suggested_term": "general",
                    "confidence": 0.5
                }

        except Exception as e:
            return {
                "symptoms_detected": [],
                "symptom_count": 0,
                "ready_for_assessment": context.turn_count >= 4,
                "suggested_pnm": "Physiological",
                "suggested_term": "general",
                "confidence": 0.3
            }

    async def _should_trigger_assessment(self, context: ConversationContext) -> bool:
        """AI-powered assessment trigger using intelligent symptom analysis"""

        # Use AI to analyze symptoms and readiness
        ai_analysis = await self._ai_analyze_symptoms_and_readiness(context)

        # Store AI analysis for later use in assessment
        context.ai_analysis = ai_analysis

        # Decision logic based on AI analysis
        if ai_analysis.get("ready_for_assessment", False):
            reason = ai_analysis.get('readiness_reason', 'AI analysis')
            return True

        # Fixed turn count trigger (no keyword matching as requested)
        if context.turn_count >= 8:  # Match the main flow threshold
            return True

        return False

    async def _ai_select_relevant_term(self, context: ConversationContext) -> tuple:
        """Use AI keyword expansion + vector search for intelligent question selection"""
        try:
            # Step 1: AI keyword expansion
            conversation_text = " ".join([msg.content for msg in context.conversation.messages[-3:] if msg.role == 'user'])
            current_input = context.user_input

            keyword_prompt = f"""Based on this ALS patient conversation, expand key medical and emotional concepts for question bank search:

Conversation: "{conversation_text}"
Current message: "{current_input}"

Generate expanded search keywords focusing on:
- Medical symptoms and conditions
- Emotional states and concerns
- Daily living activities
- Support needs and challenges

Respond with expanded keywords (comma-separated):"""

            expanded_keywords = self.llm.generate_text(keyword_prompt)
            search_query = f"{current_input} {expanded_keywords}".strip()


            # Step 2: Vector search with expanded keywords
            rag_client = RAGQueryClient()
            search_results = rag_client.search(search_query, top_k=5, index_kind="question")

            if search_results:

                # DEBUG: Print all search result metadata to understand format
                for i, result in enumerate(search_results):
                    pass  # Debug print removed

                # Get asked questions from database (not strict avoidance)
                asked_questions = context.conversation.assessment_state.get('asked_questions', [])

                # Step 3: Find best matching question from vector results
                for result in search_results:
                    # Vector search filename is question ID
                    question_id = result.get('metadata', {}).get('filename') or result.get('metadata', {}).get('id')

                    if question_id:
                        # Find corresponding question in question bank
                        all_questions = self.question_bank.items()
                        for question in all_questions:
                            if question.id == question_id:
                                # Prefer unasked questions, but don't strictly require it
                                if question_id not in asked_questions:
                                    return question.pnm, question.term
                                else:
                                    # Question was asked before, but might still be relevant
                                    return question.pnm, question.term

            # Fallback: use first unasked question from question bank
            all_questions = self.question_bank.items()
            asked_questions = context.conversation.assessment_state.get('asked_questions', [])

            for question in all_questions:
                if question.id not in asked_questions:
                    return question.pnm, question.term

            # Ultimate fallback - use first available question
            if all_questions:
                first_question = all_questions[0]
                return first_question.pnm, first_question.term

        except Exception as e:

            # Safe fallback: use first available question from question bank
            try:
                all_questions = self.question_bank.items()
                if all_questions:
                    first_question = all_questions[0]
                    return first_question.pnm, first_question.term
            except:
                pass

        # Last resort - but with real question bank term
        return "Physiological", "Mobility and transfers"

    async def _process_uc1_assessment_response(self, context: ConversationContext):
        """Process user's UC1 assessment response and record it"""
        try:
            # Get current question context from assessment state
            question_context = context.conversation.assessment_state.get('question_context', {})
            current_question_id = question_context.get('question_id')

            if current_question_id:
                # Mark this question as asked to avoid repetition
                asked_questions = context.conversation.assessment_state.get('asked_questions', [])
                if current_question_id not in asked_questions:
                    asked_questions.append(current_question_id)
                    context.conversation.assessment_state['asked_questions'] = asked_questions

                # Get current PNM/term from assessment state
                current_pnm = context.conversation.assessment_state.get('current_pnm', 'Physiological')
                current_term = context.conversation.assessment_state.get('current_term', 'General')

                # Try to get score from option first, then use AI scoring

                score = self._extract_option_score_uc1(context.user_input, question_context)

                if score is None:
                    # Use AI scoring for free text response - access ai_scorer from main manager
                    try:
                        # Ensure ai_scorer is available
                        if not hasattr(self, 'ai_scorer') or not self.ai_scorer:
                            from app.services.ai_scoring_engine import AIFreeTextScorer
                            self.ai_scorer = AIFreeTextScorer()  # No ai_router needed - uses IBM WatsonX directly

                        ai_score_result = await self.ai_scorer.score_free_text_response(
                            context.user_input,
                            question_context,
                            current_pnm,
                            context.conversation.messages[-5:]  # Recent context
                        )
                        score = ai_score_result.score

                    except Exception as e:
                        # Skip scoring instead of using hardcoded fallback as per user requirements
                        score = None
                else:
                    pass  # Debug print removed

                # Store score in conversation_scores table (like UC2)
                # Access storage through the main manager
                if self.main_manager and hasattr(self.main_manager, 'storage') and score is not None:
                    # Determine scoring method based on how score was extracted
                    score_from_option = self._extract_option_score_uc1(context.user_input, question_context)
                    scoring_method = "question_bank_options" if score_from_option is not None else "ai_fallback"

                    self.main_manager.storage.add_score(
                        conversation_id=context.conversation.id,
                        pnm=current_pnm,
                        term=current_term,
                        score=float(score),
                        scoring_method=scoring_method,
                        rationale=f"UC1 {'option selection' if score_from_option else 'AI scoring'}: {context.user_input}"
                    )
                else:
                    pass  # Debug print removed

                # Also store temporary score for UC1 term completion analysis
                term_key = f"{current_pnm}_{current_term}"
                if 'temp_term_scores' not in context.conversation.assessment_state:
                    context.conversation.assessment_state['temp_term_scores'] = {}

                if term_key not in context.conversation.assessment_state['temp_term_scores']:
                    context.conversation.assessment_state['temp_term_scores'][term_key] = []

                # Add score entry with metadata
                score_entry = {
                    'question_id': current_question_id,
                    'score': score,
                    'user_response': context.user_input,
                    'timestamp': context.conversation.messages[-1].timestamp if context.conversation.messages else None
                }
                context.conversation.assessment_state['temp_term_scores'][term_key].append(score_entry)

        except Exception as e:
            log.error(f"[UC1] Error processing assessment response: {e}")

    def _extract_option_score_uc1(self, user_input: str, question_context: dict) -> float:
        """Extract score from UC1 option selection - compatible with UC2 format"""
        try:
            options = question_context.get('options', [])
            if not options:
                return None

            user_input_lower = user_input.lower().strip()

            # Try to match by option ID first (same as UC2)
            for option in options:
                if option.get('id', '').lower() == user_input_lower:
                    score_value = option.get('score')
                    if score_value is not None:
                        return float(score_value)
                    return None

            # Try ordinal matching: user inputs 1,2,3,4 for 1st,2nd,3rd,4th option
            try:
                ordinal_input = int(user_input_lower)
                if 1 <= ordinal_input <= len(options):
                    selected_option = options[ordinal_input - 1]  # Convert 1-based to 0-based index
                    score_value = selected_option.get('score')
                    if score_value is not None:
                        return float(score_value)
                    return None
            except ValueError:
                pass  # Not a valid integer, continue to label matching

            # Try to match by option label (same as UC2)
            for option in options:
                label = option.get('label', '').lower()
                if label and user_input_lower in label:
                    score_value = option.get('score')
                    if score_value is not None:
                        return float(score_value)
                    return None

            return None
        except Exception as e:
            return None

    def _is_uc1_term_complete(self, context: ConversationContext) -> bool:
        """Determine if UC1 assessment is complete (1 main question + follow up = 2 questions total)"""
        try:
            # UC1: Complete after main question + follow up (2 questions total)
            asked_questions = context.conversation.assessment_state.get('asked_questions', [])
            total_questions_asked = len(asked_questions)

            # Complete after 2 questions: main question + follow up
            is_complete = total_questions_asked >= 2


            return is_complete
        except Exception as e:
            return False

    async def _generate_uc1_summary(self, context: ConversationContext) -> DialogueResponse:
        """Generate UC1 term assessment summary and mark conversation as completed"""
        try:

            # Get term assessment data
            current_pnm = context.conversation.assessment_state.get('current_pnm', 'Physiological')
            current_term = context.conversation.assessment_state.get('current_term', 'General')
            term_key = f"{current_pnm}_{current_term}"

            # Get collected scores
            temp_scores = context.conversation.assessment_state.get('temp_term_scores', {})
            scores_data = temp_scores.get(term_key, [])

            # Calculate average score for the term
            if scores_data:
                valid_scores = [entry['score'] for entry in scores_data if entry['score'] is not None]
                average_score = sum(valid_scores) / len(valid_scores) if valid_scores else None
            else:
                average_score = None  # No fallback score


            # Generate summary using RAG + LLM
            summary_content = await self._generate_term_summary_content(
                context, current_pnm, current_term, average_score, scores_data
            )

            # Mark conversation as completed
            if hasattr(self, 'storage'):
                context.conversation.status = 'completed'
                context.conversation.assessment_state['conversation_locked'] = True
                from datetime import datetime
                context.conversation.assessment_state['completed_at'] = datetime.now().isoformat()
                self.storage.update_conversation(context.conversation)
            else:
                pass  # Debug print removed

            return DialogueResponse(
                content=summary_content,
                response_type=ResponseType.SUMMARY,
                mode=ConversationMode.DIMENSION_ANALYSIS,
                should_continue_dialogue=False,
                current_pnm=current_pnm,
                current_term=current_term,
                options=[]  # No options for summary
            )

        except Exception as e:
            log.error(f"UC1 summary generation error: {e}")

            # Return a basic summary on error
            return DialogueResponse(
                content=f"Thank you for completing the {current_term} assessment. Based on your responses, I've gained valuable insights into your current situation and needs.",
                response_type=ResponseType.SUMMARY,
                mode=ConversationMode.DIMENSION_ANALYSIS,
                should_continue_dialogue=False
            )

    async def _generate_term_summary_content(self, context: ConversationContext, pnm: str, term: str, avg_score: float, scores_data: list) -> str:
        """Generate detailed term assessment summary using enhanced RAG + LLM with full conversation history"""
        try:
            # Collect FULL conversation history for comprehensive summary
            all_messages = context.conversation.messages if context.conversation.messages else []
            user_responses = [msg.content for msg in all_messages if msg.role == 'user']
            assistant_questions = [msg.content for msg in all_messages if msg.role == 'assistant']

            # Build conversation context with interleaved flow like UC2
            conversation_context = []
            max_length = max(len(user_responses), len(assistant_questions))
            for i in range(max_length):
                if i < len(assistant_questions):
                    conversation_context.append(f"Question: {assistant_questions[i][:200]}...")
                if i < len(user_responses):
                    conversation_context.append(f"Your response: {user_responses[i]}")

            conversation_summary = "\n".join(conversation_context[-8:])  # Last 8 exchanges

            # Enhanced RAG knowledge retrieval with Hybrid Retrieval + Self-RAG
            knowledge_context = self._retrieve_uc1_support_knowledge(pnm, term, avg_score, user_responses)

            # Improved knowledge handling like UC2
            if knowledge_context:
                knowledge_text = "\n".join([
                    f"- {doc.get('text', '')[:150]}" for doc in knowledge_context if doc.get('text', '').strip()
                ])
            else:
                knowledge_text = ""

            # If no knowledge retrieved, provide basic guidance
            if not knowledge_text.strip():
                knowledge_text = f"""- Regular monitoring and adaptation of strategies is important for {pnm} concerns
- Professional healthcare team consultation can provide personalized guidance for {term}
- Support groups and peer connections offer valuable shared experiences and coping strategies
- Assistive technologies and adaptive equipment may help maintain independence and quality of life"""

            # UC2-style professional summary format
            summary_prompt = f"""Based on your {pnm} assessment conversation about {term}, here's what we discussed:

{conversation_summary}

Professional support resources:
{knowledge_text}

Provide a professional assessment summary with targeted analysis:

## Assessment Overview:
Briefly summarize your current situation with {term} (average score: {avg_score:.1f}/7).

## Key Findings:
 Identify 2-3 specific areas where you're managing well
 Highlight 2-3 areas that may need attention or support

## Personalized Recommendations:
 Provide specific, actionable strategies based on your responses
 Reference appropriate support resources or interventions
 Consider your individual circumstances and preferences

## Next Steps:
Suggest concrete actions you can take to improve your situation.

IMPORTANT:
- Use second person (you, your) throughout - speak directly to the person
- Include proper line breaks between sections
- Be specific about their actual responses rather than generic
- Make each point targeted to what they actually shared
- Use caring but professional tone"""

            # Generate summary using LLM
            generated_summary = self.llm.generate_text(summary_prompt).strip()

            if generated_summary:
                return generated_summary
            else:
                # Enhanced fallback summary
                return f"""## Assessment Overview:
Thank you for completing your {term} assessment with an average score of {avg_score:.1f} out of 7.

## Key Findings:
 You've shared valuable insights about your {term} experiences
 Your responses show both strengths and areas for potential support

## Personalized Recommendations:
 Continue monitoring how {term} affects your daily life
 Consider discussing these findings with your healthcare team
 Explore support resources that align with your specific needs

## Next Steps:
Regular reassessment can help track changes and adapt your care plan accordingly."""

        except Exception as e:
            return f"""## Assessment Overview:
Thank you for completing your {term} assessment. Your responses help me understand your current situation better.

## Key Findings:
 You've provided important information about your experiences
 This assessment contributes to a better understanding of your needs

## Next Steps:
Continue working with your healthcare team to address your concerns and optimize your care plan."""

    async def _handle_assessment_phase(self, context: ConversationContext) -> DialogueResponse:
        """Structured assessment phase with AI-selected term"""
        try:
            # STEP 1: Process user response if provided (score and record it)
            if context.user_input.strip():
                await self._process_uc1_assessment_response(context)

                # STEP 2: Check if UC1 term is complete after processing response
                if self._is_uc1_term_complete(context):
                    return await self._generate_uc1_summary(context)

            # Get current assessment progress
            assessment_state = context.conversation.assessment_state or {}
            asked_questions = assessment_state.get('asked_questions', [])

            # Use AI to select the most relevant term for assessment
            selected_pnm, selected_term = await self._ai_select_relevant_term(context)

            # UC1 Single-term assessment: Focus on AI-selected term without strict asked_questions checking
            # As per user feedback: ","
            relevant_questions = []

            # Primary: Find questions for the AI-selected term
            for item in self.qb.items():
                if (item.pnm == selected_pnm and item.term == selected_term):
                    relevant_questions.append(item)

            # Secondary: If no specific term questions, use any questions in the PNM dimension
            if not relevant_questions:
                for item in self.qb.items():
                    if item.pnm == selected_pnm:
                        relevant_questions.append(item)

            # UC1 strategy: Select the first few questions from relevant set (up to 3 for single-term assessment)
            # This allows completing term assessment without exhaustive questioning
            max_questions_for_uc1 = 3
            available_questions = relevant_questions[:max_questions_for_uc1] if relevant_questions else []

            # Select question prioritizing unasked ones, but allowing re-asking if needed for UC1 completion
            question_item = None
            for item in available_questions:
                if item.id not in asked_questions:
                    question_item = item
                    break

            # If all prioritized questions were asked, use first available for UC1 completion
            if not question_item and available_questions:
                question_item = available_questions[0]

            # Final fallback: any question from question bank
            if not question_item:
                for item in self.qb.items():
                    question_item = item
                    break

            if question_item:

                # Get question content - handle different field names
                question_content = getattr(question_item, 'main', None) or getattr(question_item, 'question', None) or f"Question {question_item.id}"

                options = []
                if question_item.options:
                    options = [
                        {"value": opt.get("id", opt.get("value", str(i))),
                         "label": opt.get("label", opt.get("text", str(opt)))}
                        for i, opt in enumerate(question_item.options)
                    ]

                print(f"   content: '{question_content}' (type: {type(question_content)})")
                try:
                    print(f"   response_type: {ResponseType.QUESTION} (type: {type(ResponseType.QUESTION)})")
                except Exception as e:
                    print(f"   response_type ERROR: {e}")
                try:
                    print(f"   mode: {ConversationMode.DIMENSION_ANALYSIS} (type: {type(ConversationMode.DIMENSION_ANALYSIS)})")
                except Exception as e:
                    print(f"   mode ERROR: {e}")
                try:
                    print(f"   pnm: '{question_item.pnm}' (type: {type(question_item.pnm)})")
                except Exception as e:
                    print(f"   pnm ERROR: {e}")
                try:
                    print(f"   term: '{question_item.term}' (type: {type(question_item.term)})")
                except Exception as e:
                    print(f"   term ERROR: {e}")

                # Save question context for scoring (same format as UC2)
                context.conversation.assessment_state['question_context'] = {
                    'question_id': question_item.id,
                    'question': question_content,
                    'text': question_content,  # fallback for compatibility
                    'options': question_item.options,  # Original options with scores (critical!)
                    'pnm': question_item.pnm,
                    'term': question_item.term
                }

                # Update current PNM and term in assessment state
                context.conversation.assessment_state['current_pnm'] = question_item.pnm
                context.conversation.assessment_state['current_term'] = question_item.term


                try:
                    result = DialogueResponse(
                        content=question_content,
                        response_type=ResponseType.QUESTION,
                        mode=ConversationMode.DIMENSION_ANALYSIS,
                        should_continue_dialogue=False,
                        options=options,
                        current_pnm=question_item.pnm,
                        current_term=question_item.term
                    )
                    return result
                except Exception as e:
                    raise e
            else:
                # Fallback question
                return DialogueResponse(
                    content="How are you feeling about your current situation with ALS?",
                    response_type=ResponseType.QUESTION,
                    mode=ConversationMode.DIMENSION_ANALYSIS,
                    should_continue_dialogue=False,
                    options=[
                        {"value": "good", "label": "I'm managing well"},
                        {"value": "concerned", "label": "I have some concerns"},
                        {"value": "overwhelmed", "label": "I feel overwhelmed"}
                    ]
                )
        except Exception as e:
            log.error(f"Assessment phase error: {e}")
            return await self._handle_free_dialogue_phase(context)


class UseCaseTwoManager:
    """
    Use Case 2: Single dimension PNM traversal scoring manager.

    Handles: immediate assessment entry  traverse specified dimension questions  dimension summary
    """

    def __init__(self, qb: QuestionBank, ai_router: AIRouter, main_manager=None):
        self.qb = qb
        self.ai_router = ai_router
        self.main_manager = main_manager
        self.response_generator = ResponseGenerator()

    async def handle_dimension_assessment(self, context: ConversationContext, dimension: str) -> DialogueResponse:
        """Handle single dimension assessment flow"""


        try:
            assessment_state_keys = list(context.conversation.assessment_state.keys()) if context.conversation.assessment_state else []
        except Exception as e:
            raise

        # Process user's previous answer and score if provided
        # UC2 uses dedicated scoring logic for term-based evaluation
        if context.user_input and context.user_input.strip():

            # Clear any old scoring artifacts to avoid conflicts
            if 'temp_term_scores' in context.conversation.assessment_state:
                del context.conversation.assessment_state['temp_term_scores']

            try:
                # NEW SIMPLE UC2 SCORING LOGIC
                await self._process_user_response_uc2_simple(context, dimension)

                # CRITICAL FIX: Increment question index after user response processing
                # This ensures the next question selection uses the correct index
                dimension_term_question_key = f"{dimension}_term_question_index"
                current_question_index = context.conversation.assessment_state.get(dimension_term_question_key, 0)
                next_question_index = current_question_index + 1
                context.conversation.assessment_state[dimension_term_question_key] = next_question_index

                # Check if scores were added
                temp_scores = {}
                for key, value in context.conversation.assessment_state.items():
                    if 'temp_scores_' in key:
                        temp_scores[key] = value

            except Exception as e:
                print(f"[UC2] CRITICAL ERROR in scoring process: {e}")
                import traceback
                print(f"[UC2] Traceback: {traceback.format_exc()}")
                # Don't re-raise the exception - continue with question generation

            # CRITICAL FIX: Always check for term completion after user response, even if scoring failed
            try:
                await self._check_and_handle_term_completion_uc2(context, dimension)
            except Exception as completion_error:
                import traceback

        # Check if dimension is ready for summary
        if context.conversation.assessment_state.get(f"{dimension}_ready_for_summary", False):
            return await self._generate_dimension_summary_uc2(context, dimension)

        # Get all questions for this dimension and group by term
        try:
            main_questions = self.qb.for_pnm(dimension)
        except Exception as e:
            print(f"[UC2] CRITICAL ERROR getting questions for {dimension}: {e}")
            import traceback
            # Return a simple error response rather than crashing
            return DialogueResponse(
                content=f"Unable to load questions for {dimension} dimension. Please try again.",
                response_type=ResponseType.CHAT,
                mode=ConversationMode.DIMENSION_ANALYSIS,
                current_pnm=dimension
            )

        # Group questions by term
        try:
            terms_questions = {}
            for main_q in main_questions:
                term = main_q.term if hasattr(main_q, 'term') else 'General'
                if term not in terms_questions:
                    terms_questions[term] = []

                # Add main question
                terms_questions[term].append(main_q)

                # Add follow-up questions for this term
                followups = []
                if hasattr(main_q, 'followups') and main_q.followups:
                    followups = main_q.followups
                elif hasattr(main_q, 'followup_questions') and main_q.followup_questions:
                    followups = main_q.followup_questions

                # Convert follow-ups to question-like objects
                from app.services.question_bank import QuestionItem
                for i, followup in enumerate(followups):
                    # Parse followup if it's a string (JSON string)
                    parsed_followup = followup
                    if isinstance(followup, str):
                        try:
                            import json
                            parsed_followup = json.loads(followup.replace("'", '"'))  # Convert single quotes to double quotes
                        except (json.JSONDecodeError, Exception) as e:
                            continue

                    # Skip if followup is not a dictionary
                    if not isinstance(parsed_followup, dict):
                        continue

                    # Extract question text from followup properly (follow-ups use 'text' field)
                    question_text = parsed_followup.get('text', parsed_followup.get('question', parsed_followup.get('main', '')))

                    # Get followup options
                    followup_options = parsed_followup.get('options', [])

                    # Skip followups that have no question text or no options (both needed for assessment)
                    if not question_text or not followup_options:
                        continue

                    # Create meaningful fallback for missing question text
                    if not question_text:
                        question_text = f"Follow-up question {i+1} for {term}"


                    followup_q = QuestionItem(
                        id=f"{main_q.id}_followup_{i+1}",
                        pnm=dimension,
                        term=term,
                        main=question_text,
                        followups=[],  # Follow-ups don't have their own follow-ups
                        terms=[],      # Use empty terms list for follow-ups
                        meta={},       # Empty metadata
                        options=followup_options
                    )
                    terms_questions[term].append(followup_q)

        except Exception as e:
            import traceback
            raise

        # Get ordered list of terms for this dimension
        ordered_terms = sorted(terms_questions.keys())

        # Get current term and question progress within term
        dimension_term_question_key = f"{dimension}_term_question_index"

        current_term_index = context.conversation.assessment_state.get(f"{dimension}_term_index", 0)
        current_term_question_index = context.conversation.assessment_state.get(dimension_term_question_key, 0)




        # Check if we've completed all terms in this dimension
        if current_term_index >= len(ordered_terms):
            return await self._generate_dimension_summary_uc2(context, dimension)

        # Get current term and its questions
        current_term = ordered_terms[current_term_index]
        current_term_questions = terms_questions[current_term]


        # Check if current term is completed
        if current_term_question_index >= len(current_term_questions):
            try:
                await self._trigger_term_scoring_uc2(context, dimension, current_term)
            except Exception as e:
                import traceback
                raise

            # Move to next term
            next_term_index = current_term_index + 1
            context.conversation.assessment_state[f"{dimension}_term_index"] = next_term_index
            context.conversation.assessment_state[dimension_term_question_key] = 0  # Reset question index for new term

            # Check if we've completed all terms
            if next_term_index >= len(ordered_terms):
                return await self._generate_dimension_summary_uc2(context, dimension)

            # Move to first question of next term
            current_term = ordered_terms[next_term_index]
            current_term_questions = terms_questions[current_term]
            current_term_question_index = 0


        # Select current question from current term with bounds checking
        if current_term_question_index >= len(current_term_questions):
            # Force term completion
            await self._trigger_term_scoring_uc2(context, dimension, current_term)
            next_term_index = current_term_index + 1
            context.conversation.assessment_state[f"{dimension}_term_index"] = next_term_index

            if next_term_index >= len(ordered_terms):
                return await self._generate_dimension_summary_uc2(context, dimension)

            # Move to next term
            current_term = ordered_terms[next_term_index]
            current_term_questions = terms_questions[current_term]
            current_term_question_index = 0
            context.conversation.assessment_state[dimension_term_question_key] = 1

        question_item = current_term_questions[current_term_question_index]

        # Question index will be incremented after user responds and scores question

        return self._generate_dimension_question(question_item, dimension, context)

    def _generate_dimension_question(self, question_item, dimension: str, context: ConversationContext = None) -> DialogueResponse:
        """Generate dimension question with proper question_context setup"""
        options = []
        if question_item.options:
            options = []
            for i, opt in enumerate(question_item.options):
                if isinstance(opt, dict):
                    # Option is a dictionary
                    options.append({
                        "value": opt.get("id", opt.get("value", str(i))),
                        "label": opt.get("label", opt.get("text", str(opt)))
                    })
                else:
                    # Option is a string or other type
                    options.append({
                        "value": str(i),
                        "label": str(opt)
                    })

        # Set question_context for scoring (CRITICAL for UC2 scoring)
        if context:
            question_context = {
                'question': question_item.main,
                'text': question_item.main,  # fallback for compatibility
                'options': question_item.options,  # Original options with scores
                'question_id': question_item.id,
                'pnm': dimension,
                'term': question_item.term
            }
            context.conversation.assessment_state['question_context'] = question_context

            # AI question storage is handled by chat_unified.py centralized storage

        return DialogueResponse(
            content=question_item.main,
            response_type=ResponseType.QUESTION,
            mode=ConversationMode.DIMENSION_ANALYSIS,
            should_continue_dialogue=False,
            options=options,
            current_pnm=dimension,
            current_term=question_item.term,
            question_id=question_item.id
        )

    async def _generate_dimension_summary(self, context: ConversationContext, dimension: str) -> DialogueResponse:
        """Generate professional RAG AI summary for dimension completion"""
        try:
            # Use RAG-enhanced professional summary generation
            summary_content = self.response_generator.generate_summary_response(context)
        except Exception as e:
            # AI fallback without hardcoded templates
            scores = context.conversation.assessment_state.get('scores', {}).get(dimension, {})
            if scores:
                avg_score = sum(score_data['score'] for score_data in scores.values()) / len(scores)
                summary_content = f"Assessment complete for {dimension}. Average score: {avg_score:.1f}/7. Your responses provide valuable insights into your current situation and will guide personalized support recommendations."
            else:
                summary_content = f"Your {dimension} assessment has been completed. Thank you for sharing your experiences. This information will help us better understand your needs and provide appropriate support."

        return DialogueResponse(
            content=summary_content,
            response_type=ResponseType.SUMMARY,
            mode=ConversationMode.DIMENSION_ANALYSIS,
            should_continue_dialogue=False,
            current_pnm=dimension
        )

    def _extract_score_from_user_input(self, user_input: str, question_context: dict) -> float:
        """Extract score from user input using question context options"""
        if not user_input or not question_context or 'options' not in question_context:
            return None

        options = question_context.get('options', [])
        user_input_lower = user_input.lower().strip()


        # Try to match by option ID first
        for option in options:
            if option.get('id', '').lower() == user_input_lower:
                score_value = option.get('score')
                if score_value is not None:
                    return float(score_value)
                return None  # No score for this option

        # Try ordinal matching: user inputs 1,2,3,4 for 1st,2nd,3rd,4th option
        try:
            ordinal_input = int(user_input_lower)
            if 1 <= ordinal_input <= len(options):
                selected_option = options[ordinal_input - 1]  # Convert 1-based to 0-based index
                score_value = selected_option.get('score')
                if score_value is not None:
                    return float(score_value)
                return None  # No score for this option
        except ValueError:
            pass  # Not a valid integer, continue to label matching

        # Try to match by option label
        for option in options:
            label = option.get('label', '').lower()
            if label and user_input_lower in label:
                score_value = option.get('score')
                if score_value is not None:
                    return float(score_value)
                return None  # No score for this option

        return None

    async def _process_user_response_uc2_simple(self, context: ConversationContext, dimension: str) -> None:
        """
        Simple UC2 scoring logic based on user requirements:
        1. Extract score from main question options
        2. Store immediately for term completion
        3. Trigger term scoring when term is complete
        """
        if not context.user_input or not context.user_input.strip():
            return

        user_input = context.user_input.strip()

        # Get question context with options
        question_context = context.conversation.assessment_state.get('question_context', {})

        # Check if question_context has term data
        if not question_context.get('term'):
            pass  # Debug print removed

        # Extract score from user input using existing method
        score = self._extract_score_from_user_input(user_input, question_context)
        scoring_method = "question_bank_options"

        if score is None:
            # AI scoring fallback for custom user input (as per CLAUDE.md requirements)
            try:
                # Ensure ai_scorer is always available
                if not hasattr(self, 'ai_scorer') or not self.ai_scorer:
                    from app.services.ai_scoring_engine import AIFreeTextScorer
                    self.ai_scorer = AIFreeTextScorer()  # No ai_router needed - uses IBM WatsonX directly

                ai_score_result = await self.ai_scorer.score_free_text_response(
                    user_input,
                    question_context,
                    dimension,
                    context.conversation.messages[-5:]  # Recent context
                )
                score = ai_score_result.score
                scoring_method = "ai_fallback"

            except Exception as e:
                # Skip scoring instead of using hardcoded fallback as per user requirements
                return

        if score is not None:
            # Get current term from question context with fallback to current context
            current_term = question_context.get('term')
            if not current_term:
                # Fallback to context.current_term or dimension-based term
                current_term = getattr(context, 'current_term', None)
                if not current_term:
                    # Skip scoring if no valid term is available - prevent wrong data
                    return


            # Store term score directly in database (immediate storage)
            await self._store_term_score_immediate(context, dimension, current_term, score, scoring_method)

            # Mark this term as completed
            completed_terms = context.conversation.assessment_state.get('completed_terms', [])
            term_key = f"{dimension}_{current_term}"
            if term_key not in completed_terms:
                completed_terms.append(term_key)
                context.conversation.assessment_state['completed_terms'] = completed_terms
        else:
            pass  # Debug print removed

    async def _store_term_score_immediate(self, context: ConversationContext, dimension: str, term: str, score: float, scoring_method: str = "question_bank_options") -> bool:
        """
        Immediately store term score to database
        Returns True if successful, False otherwise
        """
        try:
            from datetime import datetime
            import sqlite3
            from pathlib import Path


            # Database path
            db_path = Path(__file__).parent.parent / "data" / "als.db"

            if not db_path.exists():
                return False

            # Connect and store
            with sqlite3.connect(str(db_path)) as conn:
                conn.execute("""
                    INSERT OR REPLACE INTO conversation_scores
                    (conversation_id, pnm, term, score, status, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?)
                """, (
                    context.conversation.id,
                    dimension,
                    term,
                    float(score),
                    'completed',
                    datetime.now().isoformat()
                ))

                # Verify storage
                result = conn.execute(
                    "SELECT score FROM conversation_scores WHERE conversation_id = ? AND pnm = ? AND term = ?",
                    (context.conversation.id, dimension, term)
                ).fetchone()

                if result:
                    return True
                else:
                    return False

        except Exception as e:
            print(f"[UC2] CRITICAL ERROR storing score: {e}")
            return False

    async def _trigger_term_scoring_uc2(self, context: ConversationContext, dimension: str, term: str) -> None:
        """
        Simple term completion for UC2 - just mark term as completed
        Score has already been stored directly in database
        """

        # Mark this term as completed in assessment state
        completed_terms = context.conversation.assessment_state.get('completed_terms', [])
        term_key = f"{dimension}_{term}"
        if term_key not in completed_terms:
            completed_terms.append(term_key)
            context.conversation.assessment_state['completed_terms'] = completed_terms

    async def _generate_dimension_summary_uc2(self, context: ConversationContext, dimension: str) -> DialogueResponse:
        """Generate professional RAG AI summary for dimension completion and lock conversation"""

        # Check if summary already generated to prevent duplicate
        dimension_completed_key = f"{dimension}_completed"
        if context.conversation.assessment_state.get(dimension_completed_key, False):
            return DialogueResponse(
                content=f"Assessment for {dimension} dimension has been completed. Thank you for your responses.",
                response_type=ResponseType.SUMMARY,
                mode=ConversationMode.DIMENSION_ANALYSIS,
                should_continue_dialogue=False,
                current_pnm=dimension
            )

        try:
            # Use RAG-enhanced professional summary generation
            summary_content = self.response_generator.generate_summary_response(context)

            # Mark this dimension as completed and lock conversation
            context.conversation.assessment_state[dimension_completed_key] = True
            context.conversation.assessment_state['conversation_locked'] = True

            # AI summary storage is handled by chat_unified.py centralized storage

            return DialogueResponse(
                content=summary_content,
                response_type=ResponseType.SUMMARY,
                mode=ConversationMode.DIMENSION_ANALYSIS,
                should_continue_dialogue=False,
                current_pnm=dimension
            )

        except Exception as e:
            # Fallback summary
            context.conversation.assessment_state[dimension_completed_key] = True
            context.conversation.assessment_state['conversation_locked'] = True

            fallback_summary = f"Thank you for completing the {dimension} assessment. Your responses have been recorded and will help provide personalized support recommendations."

            # AI fallback summary storage is handled by chat_unified.py centralized storage

            return DialogueResponse(
                content=fallback_summary,
                response_type=ResponseType.SUMMARY,
                mode=ConversationMode.DIMENSION_ANALYSIS,
                should_continue_dialogue=False,
                current_pnm=dimension
            )

    async def _check_and_handle_term_completion_uc2(self, context: ConversationContext, dimension: str) -> None:
        """Check if current term is completed after user response and trigger scoring if needed"""

        try:
            # Get term progress information
            main_questions = self.qb.for_pnm(dimension)
            terms_questions = {}
            for main_q in main_questions:
                term = main_q.term if hasattr(main_q, 'term') else 'General'
                if term not in terms_questions:
                    terms_questions[term] = []
                terms_questions[term].append(main_q)

            ordered_terms = sorted(terms_questions.keys())
            current_term_index = context.conversation.assessment_state.get(f"{dimension}_term_index", 0)

            if current_term_index >= len(ordered_terms):
                return

            current_term = ordered_terms[current_term_index]
            current_term_questions = terms_questions[current_term]
            dimension_term_question_key = f"{dimension}_term_question_index"
            current_term_question_index = context.conversation.assessment_state.get(dimension_term_question_key, 0)

            print(f"  - current_term_index: {current_term_index}")
            print(f"  - current_term: {current_term}")
            print(f"  - current_term_question_index: {current_term_question_index}")
            print(f"  - len(current_term_questions): {len(current_term_questions)}")
            print(f"  - Completion condition: {current_term_question_index} >= {len(current_term_questions)} = {current_term_question_index >= len(current_term_questions)}")

            # Check if current term is now completed (no more questions in this term)
            # Note: question index has already been incremented after user response processing
            if current_term_question_index >= len(current_term_questions):

                # Mark this term as completed
                completed_terms = context.conversation.assessment_state.get('completed_terms', [])
                term_key = f"{dimension}_{current_term}"
                if term_key not in completed_terms:
                    completed_terms.append(term_key)
                    context.conversation.assessment_state['completed_terms'] = completed_terms

                # Move to next term
                next_term_index = current_term_index + 1
                context.conversation.assessment_state[f"{dimension}_term_index"] = next_term_index
                context.conversation.assessment_state[dimension_term_question_key] = 0


                # Check if all terms completed
                if next_term_index >= len(ordered_terms):
                    # Set flag to trigger summary generation on next response
                    context.conversation.assessment_state[f"{dimension}_ready_for_summary"] = True

                return

            # SIMPLIFIED UC2: Check if this term has been completed (legacy code)
            completed_terms = context.conversation.assessment_state.get('completed_terms', [])
            term_key = f"{dimension}_{current_term}"

            if term_key in completed_terms:

                # Move to next term
                next_term_index = current_term_index + 1
                context.conversation.assessment_state[f"{dimension}_term_index"] = next_term_index
                context.conversation.assessment_state[dimension_term_question_key] = 0


                # Check if all terms completed
                if next_term_index >= len(ordered_terms):
                    # Set flag to trigger summary generation on next response
                    context.conversation.assessment_state[f"{dimension}_ready_for_summary"] = True

        except Exception as e:
            import traceback
            print(f"[UC2] Traceback: {traceback.format_exc()}")

    async def _evaluate_term_with_ai(self, dimension: str, term: str, responses: list, main_score: float) -> float:
        """AI-powered evaluation of term responses to complement main question score"""

        if not responses:
            return main_score

        try:
            # Use existing AI scoring engine with focused prompt
            evaluation_prompt = f"""
            Evaluate the user's responses for {dimension} dimension, {term} term.

            Main question score: {main_score}/7 (0=best condition, 7=most challenging)

            User responses: {' | '.join(responses[-3:])}

            Consider:
            - Consistency with main question score
            - Quality of life impact indicated in responses
            - Practical challenges mentioned
            - Overall functioning level

            Return a score from 0-7 where:
            0 = Excellent functioning, minimal challenges
            3.5 = Moderate challenges, some impact
            7 = Severe challenges, significant impact

            Score:"""

            # Use AI scorer for consistent evaluation
            ai_result = await self.ai_scorer.score_free_text_response(
                ' '.join(responses[-3:]),  # Last 3 responses
                {"prompt": evaluation_prompt},
                dimension,
                []  # No context needed for term evaluation
            )

            ai_score = float(ai_result.score) if ai_result.score is not None else main_score

            # Ensure score is in valid range
            ai_score = max(0.0, min(7.0, ai_score))
            return ai_score

        except Exception as e:
            return main_score


